{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective of the notebook:\n",
    "\n",
    "In this notebook, we will analyze results of the final model.\n",
    "\n",
    "- Create confusion matrix\n",
    "- Create feature importance chart\n",
    "- Visualize model predictions in order-recency bins matrix\n",
    "- Analyze model performance in order-recency bins matrix\n",
    "- Save client_id, y_pred, y_actual results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T18:36:26.674088Z",
     "start_time": "2020-10-14T18:36:24.943058Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaan.simsek/anaconda3/envs/forecasting/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import lightgbm \n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "break_point = datetime(2017, 2, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T18:36:26.681684Z",
     "start_time": "2020-10-14T18:36:26.676946Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    print('Reading files...')    \n",
    "    order_df = pd.read_csv('../input/machine_learning_challenge_order_data.csv')\n",
    "    print('Order data has {} rows and {} columns'.format(order_df.shape[0], order_df.shape[1]))\n",
    "    label_df = pd.read_csv('../input/machine_learning_challenge_labeled_data.csv')\n",
    "    print('Label data has {} rows and {} columns'.format(label_df.shape[0], label_df.shape[1]))\n",
    "    df = order_df.merge(label_df, on='customer_id')\n",
    "    print('The final data has {} rows and {} columns'.format(df.shape[0], df.shape[1]))\n",
    "    print(\"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T20:03:09.358138Z",
     "start_time": "2020-10-12T20:03:09.231156Z"
    }
   },
   "source": [
    "### Change data types and reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T18:36:26.689289Z",
     "start_time": "2020-10-14T18:36:26.684401Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=False):\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    int_columns = df.select_dtypes(include=[\"int\"]).columns\n",
    "    float_columns = df.select_dtypes(include=[\"float\"]).columns\n",
    "\n",
    "    for col in int_columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
    "\n",
    "    for col in float_columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"float\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    print(\"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T18:36:26.695928Z",
     "start_time": "2020-10-14T18:36:26.692373Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "\n",
    "    for i in ['restaurant_id', 'city_id', 'payment_id', 'platform_id', 'transmission_id']:\n",
    "        df[i] = labelencoder.fit_transform(df[i])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert raw data to a session format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T18:36:26.703724Z",
     "start_time": "2020-10-14T18:36:26.697818Z"
    }
   },
   "outputs": [],
   "source": [
    "def getWeeklyDates(df, break_point):\n",
    "\n",
    "    df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "    three_day = df[df['order_date'] >= break_point - timedelta(days=3)]\n",
    "    one_week = df[df['order_date'] >= break_point - timedelta(days=7)]\n",
    "    two_week = df[df['order_date'] >= break_point - timedelta(days=14)]\n",
    "    four_week = df[df['order_date'] >= break_point - timedelta(days=28)]\n",
    "    twelve_week = df[df['order_date'] >= break_point - timedelta(days=84)]\n",
    "    twenty_four_week = df[df['order_date'] >= break_point - timedelta(days=168)]\n",
    "    all_week = df\n",
    "    return three_day, one_week, two_week, four_week, twelve_week, twenty_four_week,all_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T18:36:26.721182Z",
     "start_time": "2020-10-14T18:36:26.705573Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df, break_point):\n",
    "    \n",
    "    df['customer_order_rank'] = df['customer_order_rank'].fillna(method='ffill')\n",
    "\n",
    "    df['order_date'] = pd.to_datetime(df['order_date']) \n",
    "    df['recency'] = (break_point - df['order_date']) / np.timedelta64(1, 'D')\n",
    "    df['first_order_date'] = df.groupby(['customer_id'])['order_date'].transform('first')\n",
    "    df['age_of_user'] = (break_point - df['first_order_date']) / np.timedelta64(1, 'D')\n",
    "\n",
    "    df['year'] = df['order_date'].dt.year\n",
    "    df['month'] = df['order_date'].dt.month\n",
    "    df['week'] = df['order_date'].dt.week\n",
    "    df['day'] = df['order_date'].dt.day\n",
    "    df['dayofweek'] = df['order_date'].dt.dayofweek\n",
    "    df[\"is_weekend\"] = df[\"dayofweek\"].isin([5, 6]).astype(np.int8)\n",
    "    \n",
    "    df['demand'] = 1\n",
    "    \n",
    "    df['order_date_shift'] = df.groupby('customer_id')['order_date'].shift()\n",
    "    df['date_diff'] = (df['order_date'] - df['order_date_shift']) / np.timedelta64(1, 'D')\n",
    "\n",
    "    three_day, one_week, two_week, four_week, twelve_week, twenty_four_week,all_week = getWeeklyDates(df, break_point)\n",
    "\n",
    "    col = ['demand', 'is_failed','voucher_amount','delivery_fee', 'amount_paid', 'date_diff']\n",
    "    three_day = three_day.groupby('customer_id')[col].sum().add_prefix('three_day_').reset_index()\n",
    "    one_week = one_week.groupby('customer_id')[col].sum().add_prefix('one_week_').reset_index()\n",
    "    two_week = two_week.groupby('customer_id')[col].sum().add_prefix('two_week_').reset_index()\n",
    "    four_week = four_week.groupby('customer_id')[col].sum().add_prefix('four_week_').reset_index()\n",
    "    twelve_week = twelve_week.groupby('customer_id')[col].sum().add_prefix('twelve_week_').reset_index()\n",
    "    twenty_four_week = twenty_four_week.groupby('customer_id')[col].sum().add_prefix('twenty_four_week_').reset_index()\n",
    "    all_week = all_week.groupby('customer_id')[col].sum().add_prefix('all_week_').reset_index()\n",
    "    \n",
    "    df = df.groupby('customer_id').last().reset_index()\n",
    "    df = df.merge(three_day, how='left').merge(one_week, how='left').merge(two_week, how='left').merge(four_week,\n",
    "    'left').merge(twelve_week,'left').merge(twenty_four_week,'left').merge(all_week,'left').reset_index()\n",
    "\n",
    "    df['city_count'] = df.groupby('city_id')['customer_id'].transform('nunique')\n",
    "    df['rest_count'] = df.groupby('restaurant_id')['customer_id'].transform('nunique')\n",
    "    \n",
    "    df['city_mean'] = df.groupby('city_id')['is_returning_customer'].transform('mean')\n",
    "    df['rest_mean'] = df.groupby('restaurant_id')['is_returning_customer'].transform('mean')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the lgb model and calculate scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T18:36:26.732763Z",
     "start_time": "2020-10-14T18:36:26.722842Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_lgb(df):\n",
    "    \n",
    "    y = df['is_returning_customer']\n",
    "    X = df.drop(columns=['index', 'customer_id', 'order_date', 'is_returning_customer',\n",
    "                        'first_order_date', 'order_date_shift'])    \n",
    "    \n",
    "    clf = lightgbm.LGBMClassifier(num_leaves= 10, n_estimators= 700, min_child_weight= 5, max_depth= 9, \n",
    "                                  learning_rate= 0.05, colsample_bytree= 0.9000000000000001)\n",
    "    \n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    auc_mean = cross_val_score(clf, X, y, cv = kfold, scoring = \"roc_auc\").mean()\n",
    "    auc_std = cross_val_score(clf, X, y, cv = kfold, scoring = \"roc_auc\").std()\n",
    "\n",
    "    acc_mean = cross_val_score(clf, X, y, cv = kfold, scoring = \"accuracy\").mean()\n",
    "    acc_std = cross_val_score(clf, X, y, cv = kfold, scoring = \"accuracy\").std()\n",
    "    \n",
    "    model_result = round(pd.DataFrame({'Roc-Auc Mean':auc_mean,'Roc-Auc Std':auc_std,\n",
    "                                'Accuracy Mean':acc_mean, 'Accuracy Std':acc_std}, \n",
    "                                 index=['LGBM']), 4) \n",
    "    \n",
    "    print(model_result)\n",
    "\n",
    "    y_pred = cross_val_predict(clf, X, y, cv=kfold)\n",
    "    \n",
    "    fig, (ax0, ax1) = plt.subplots(2,1, figsize=(9,12))\n",
    "\n",
    "    sns.heatmap(confusion_matrix(y,y_pred),annot=True,fmt='2.0f', ax=ax0).set_title('Confusion matrix')\n",
    "\n",
    "    pd.Series(clf.feature_importances_,X.columns).sort_values()[-20:].plot.barh(width=0.8,\n",
    "                                            color='navy', ax=ax1).set_title('Feature Importance')\n",
    "    \n",
    "                                                                                \n",
    "    y_pred = cross_val_predict(clf, X, y, cv=kfold)\n",
    "    model_output = pd.DataFrame(y_pred, index=df.customer_id, columns=['y_pred']).reset_index()\n",
    "    model_output['y_actual'] = y\n",
    "    model_output = model_output.merge(df[['customer_id', 'customer_order_rank', 'recency']], on='customer_id')\n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-14T18:36:24.961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Order data has 786600 rows and 13 columns\n",
      "Label data has 245455 rows and 2 columns\n",
      "The final data has 786600 rows and 14 columns\n",
      "\n",
      "Mem. usage decreased to 42.76 Mb (52.5% reduction)\n",
      "\n",
      "      Roc-Auc Mean  Roc-Auc Std  Accuracy Mean  Accuracy Std\n",
      "LGBM        0.8447       0.0013         0.8461        0.0005\n"
     ]
    }
   ],
   "source": [
    "def execute_pipeline():\n",
    "    \n",
    "    df = read_data()\n",
    "    df = reduce_mem_usage(df, True)\n",
    "    df = transform_data(df)\n",
    "    df = feature_engineering(df, break_point)\n",
    "    predicted = run_lgb(df)\n",
    "    return predicted\n",
    "\n",
    "model_output = execute_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model interpretation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-14T18:36:24.964Z"
    }
   },
   "outputs": [],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-14T18:36:24.966Z"
    }
   },
   "outputs": [],
   "source": [
    "order_bins = [0, 1, 4, 9, 49, 99, 999]\n",
    "order_labels = [\"1\", \"2-4\", \"5-9\", \"10-49\", \"50-99\", \"100+\"]\n",
    "model_output['order_binned'] = pd.cut(model_output['customer_order_rank'], bins=order_bins, labels=order_labels)\n",
    "\n",
    "recency_bins = [0, 7, 14, 28, 84, 168, 1680]\n",
    "recency_labels = [\"0-7\", \"8-14\", \"15-28\", \"29-84\", \"85-168\", \"168+\"]\n",
    "model_output['recency_binned'] = pd.cut(model_output['recency'], bins=recency_bins, labels=recency_labels)\n",
    "\n",
    "model_output['is_true'] = np.where(model_output.y_pred==model_output.y_actual, 1, 0)\n",
    "\n",
    "y_actual = model_output.pivot_table(columns='order_binned', \n",
    "                                     index='recency_binned', values='y_actual', aggfunc='mean')\n",
    "y_pred = model_output.pivot_table(columns='order_binned', \n",
    "                                     index='recency_binned', values='y_pred', aggfunc='mean')\n",
    "customer_count = model_output.pivot_table(columns='order_binned', \n",
    "                                     index='recency_binned', values='y_pred', aggfunc='count')\n",
    "model_performance = model_output.pivot_table(columns='order_binned', \n",
    "                                     index='recency_binned', values='is_true', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-14T18:36:24.971Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax0,ax1) = plt.subplots(1,2, figsize=(18, 8))\n",
    "\n",
    "sns.heatmap(data = round(model_performance, 2), annot = True, cmap='Blues', fmt='g', ax=ax0)\n",
    "ax0.set_title('Model Performance (accuracy)')\n",
    "ax0.set_xlabel('Order Bins')\n",
    "ax0.set_ylabel('Recency Bins')\n",
    "\n",
    "sns.heatmap(data = round(y_pred, 2), annot = True, cmap='Blues', fmt='g', ax=ax1)\n",
    "ax1.set_title('Model Prediction (y_pred)')\n",
    "ax1.set_xlabel('Order Bins')\n",
    "ax1.set_ylabel('Recency Bins')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM model labels almost all newcomers and 168+ recency customers as churn. (right below)\n",
    "\n",
    "Model performance (y_pred=y_actual) is higher for 10+ customers but lower for 2-4 order and 12-24 week recency customer cohorts. (left below)\n",
    "\n",
    "For further analysis, the features below would increase model performance: \n",
    "\n",
    "- Rating\n",
    "- Comment\n",
    "- Delivery time\n",
    "- Live chat experience\n",
    "- Cancel reasons (courier, rest, user, etc.)\n",
    "- Age, gender, device type, district, OS type\n",
    "\n",
    "It would be good to get geolocation data because it helps to understand whether a customer in our service area currently. (holiday, business trip, etc.)\n",
    "\n",
    "We could spend more time on different models (NN, CatBoost, stacked models, etc.) or tuning hyperparameters, but there is a trade-off between the time you spent and improvement in the model scores. \n",
    "\n",
    "Now, we will create a production-ready py version of the final model."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
