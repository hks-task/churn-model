{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective of the notebook:\n",
    "\n",
    "In this notebook, we create a machine learning model pipeline to predict probabilities and calculate model scores.\n",
    "- Importing libraries\n",
    "- Importing datasets\n",
    "- Change data types and reduce memory usage\n",
    "- Label encode categorical features (Features already encoded for this task.)\n",
    "- Fill null values\n",
    "- Convert raw data to a session format\n",
    "- Run xgboost model\n",
    "- Calculate model scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T11:46:22.738380Z",
     "start_time": "2020-10-10T11:46:19.548832Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import xgboost\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "kfold = KFold(n_splits=5, random_state=42)\n",
    "break_point = datetime(2017, 2, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T11:46:22.752245Z",
     "start_time": "2020-10-10T11:46:22.743634Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    print('Reading files...')    \n",
    "    order_df = pd.read_csv('../input/machine_learning_challenge_order_data.csv')\n",
    "    print('Order data has {} rows and {} columns'.format(order_df.shape[0], order_df.shape[1]))\n",
    "    label_df = pd.read_csv('../input/machine_learning_challenge_labeled_data.csv')\n",
    "    print('Label data has {} rows and {} columns'.format(label_df.shape[0], label_df.shape[1]))\n",
    "    df = order_df.merge(label_df, on='customer_id')\n",
    "    print('The final data has {} rows and {} columns'.format(df.shape[0], df.shape[1]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change data types and reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T11:46:22.765654Z",
     "start_time": "2020-10-10T11:46:22.755444Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=False):\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    int_columns = df.select_dtypes(include=[\"int\"]).columns\n",
    "    float_columns = df.select_dtypes(include=[\"float\"]).columns\n",
    "\n",
    "    for col in int_columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
    "\n",
    "    for col in float_columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"float\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T11:46:22.776800Z",
     "start_time": "2020-10-10T11:46:22.769529Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "\n",
    "    for i in ['restaurant_id', 'city_id', 'payment_id', 'platform_id', 'transmission_id']:\n",
    "        df[i] = labelencoder.fit_transform(df[i])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert raw data to a session format\n",
    "Fill order rank with forward-fillinng method. As a baseline model, we only keep last record of each customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T11:46:22.785149Z",
     "start_time": "2020-10-10T11:46:22.779948Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df, break_point):\n",
    "\n",
    "    df['customer_order_rank'] = df['customer_order_rank'].fillna(method='ffill')\n",
    "    df = df.groupby('customer_id').last().reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run xgb model and calculate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T17:00:12.036337Z",
     "start_time": "2020-10-10T17:00:12.007711Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_lgb(df):\n",
    "    \n",
    "    y = df['is_returning_customer']\n",
    "    X = df.drop(columns=['customer_id', 'order_date', 'is_returning_customer'])    \n",
    "    \n",
    "    clf = xgboost.XGBClassifier(objective= 'binary:logistic', n_jobs= -1, scale_pos_weight=3)\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    y_pred = cross_val_predict(clf, X, y, cv=kfold)\n",
    "    \n",
    "    print('Accuracy Score:  ',round(metrics.accuracy_score(y, y_pred), 2))\n",
    "    print('Roc Auc Score:  ',round(roc_auc_score(y, y_pred), 2))\n",
    "    print('Classification Report: \\n', classification_report(y, y_pred, target_names=['0', '1']))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute all pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T17:03:13.239697Z",
     "start_time": "2020-10-10T17:00:12.410864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Order data has 786600 rows and 13 columns\n",
      "Label data has 245455 rows and 2 columns\n",
      "Mem. usage decreased to 42.76 Mb (52.5% reduction)\n",
      "Accuracy Score:   0.76\n",
      "Roc Auc Score:   0.71\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84    189948\n",
      "           1       0.48      0.62      0.54     55507\n",
      "\n",
      "   micro avg       0.76      0.76      0.76    245455\n",
      "   macro avg       0.68      0.71      0.69    245455\n",
      "weighted avg       0.79      0.76      0.77    245455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def execute_pipeline():\n",
    "    \n",
    "    df = read_data()\n",
    "    df = reduce_mem_usage(df, True)\n",
    "    df = transform_data(df)\n",
    "    df = feature_engineering(df, break_point)\n",
    "    run_lgb(df)\n",
    "    \n",
    "execute_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
