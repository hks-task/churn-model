{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective of the notebook:\n",
    "\n",
    "In this notebook, we will try different parameter combinations for the final lightGBM classfier model to increase model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T15:10:46.799850Z",
     "start_time": "2020-10-14T15:10:45.407540Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaan.simsek/anaconda3/envs/forecasting/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import lightgbm \n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "break_point = datetime(2017, 2, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T15:10:46.805180Z",
     "start_time": "2020-10-14T15:10:46.801358Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    print('Reading files...')    \n",
    "    order_df = pd.read_csv('../input/machine_learning_challenge_order_data.csv')\n",
    "    print('Order data has {} rows and {} columns'.format(order_df.shape[0], order_df.shape[1]))\n",
    "    label_df = pd.read_csv('../input/machine_learning_challenge_labeled_data.csv')\n",
    "    print('Label data has {} rows and {} columns'.format(label_df.shape[0], label_df.shape[1]))\n",
    "    df = order_df.merge(label_df, on='customer_id')\n",
    "    print('The final data has {} rows and {} columns'.format(df.shape[0], df.shape[1]))\n",
    "    print(\"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change data types and reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T15:10:46.811344Z",
     "start_time": "2020-10-14T15:10:46.806569Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=False):\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    int_columns = df.select_dtypes(include=[\"int\"]).columns\n",
    "    float_columns = df.select_dtypes(include=[\"float\"]).columns\n",
    "\n",
    "    for col in int_columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
    "\n",
    "    for col in float_columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"float\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    print(\"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T15:10:46.816664Z",
     "start_time": "2020-10-14T15:10:46.813533Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "\n",
    "    for i in ['restaurant_id', 'city_id', 'payment_id', 'platform_id', 'transmission_id']:\n",
    "        df[i] = labelencoder.fit_transform(df[i])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert raw data to a session format\n",
    "- Fill order rank with the forward-filling method.\n",
    "- Calculate recency and number of days from the first order.\n",
    "- Get time-related features like the year, month, week, day, day of the week, weekend.\n",
    "- Add day differences between consecutive orders.\n",
    "- Calculate rolling features in 3 days, 1, 2, 4, 12, 24 weeks, and all time.\n",
    "- Calculate unique customer count and churn rate by restaurant, city.\n",
    "- Keep the last record of each customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T15:10:46.822808Z",
     "start_time": "2020-10-14T15:10:46.818144Z"
    }
   },
   "outputs": [],
   "source": [
    "def getWeeklyDates(df, break_point):\n",
    "\n",
    "    df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "    three_day = df[df['order_date'] >= break_point - timedelta(days=3)]\n",
    "    one_week = df[df['order_date'] >= break_point - timedelta(days=7)]\n",
    "    two_week = df[df['order_date'] >= break_point - timedelta(days=14)]\n",
    "    four_week = df[df['order_date'] >= break_point - timedelta(days=28)]\n",
    "    twelve_week = df[df['order_date'] >= break_point - timedelta(days=84)]\n",
    "    twenty_four_week = df[df['order_date'] >= break_point - timedelta(days=168)]\n",
    "    all_week = df\n",
    "    return three_day, one_week, two_week, four_week, twelve_week, twenty_four_week,all_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T15:10:46.836952Z",
     "start_time": "2020-10-14T15:10:46.824432Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df, break_point):\n",
    "    \n",
    "    df['customer_order_rank'] = df['customer_order_rank'].fillna(method='ffill')\n",
    "\n",
    "    df['order_date'] = pd.to_datetime(df['order_date']) \n",
    "    df['recency'] = (break_point - df['order_date']) / np.timedelta64(1, 'D')\n",
    "    df['first_order_date'] = df.groupby(['customer_id'])['order_date'].transform('first')\n",
    "    df['age_of_user'] = (break_point - df['first_order_date']) / np.timedelta64(1, 'D')\n",
    "\n",
    "    df['year'] = df['order_date'].dt.year\n",
    "    df['month'] = df['order_date'].dt.month\n",
    "    df['week'] = df['order_date'].dt.week\n",
    "    df['day'] = df['order_date'].dt.day\n",
    "    df['dayofweek'] = df['order_date'].dt.dayofweek\n",
    "    df[\"is_weekend\"] = df[\"dayofweek\"].isin([5, 6]).astype(np.int8)\n",
    "    \n",
    "    df['demand'] = 1\n",
    "    \n",
    "    df['order_date_shift'] = df.groupby('customer_id')['order_date'].shift()\n",
    "    df['date_diff'] = (df['order_date'] - df['order_date_shift']) / np.timedelta64(1, 'D')\n",
    "\n",
    "    \n",
    "    three_day, one_week, two_week, four_week, twelve_week, twenty_four_week,all_week = getWeeklyDates(df, break_point)\n",
    "    \n",
    "    col = ['demand', 'is_failed','voucher_amount','delivery_fee', 'amount_paid', 'date_diff']\n",
    "    three_day = three_day.groupby('customer_id')[col].sum().add_prefix('three_day_').reset_index()\n",
    "    one_week = one_week.groupby('customer_id')[col].sum().add_prefix('one_week_').reset_index()\n",
    "    two_week = two_week.groupby('customer_id')[col].sum().add_prefix('two_week_').reset_index()\n",
    "    four_week = four_week.groupby('customer_id')[col].sum().add_prefix('four_week_').reset_index()\n",
    "    twelve_week = twelve_week.groupby('customer_id')[col].sum().add_prefix('twelve_week_').reset_index()\n",
    "    twenty_four_week = twenty_four_week.groupby('customer_id')[col].sum().add_prefix('twenty_four_week_').reset_index()\n",
    "    all_week = all_week.groupby('customer_id')[col].sum().add_prefix('all_week_').reset_index()\n",
    "    \n",
    "    df = df.groupby('customer_id').last().reset_index()\n",
    "    df = df.merge(three_day, how='left').merge(one_week, how='left').merge(two_week, how='left').merge(four_week,\n",
    "    'left').merge(twelve_week,'left').merge(twenty_four_week,'left').merge(all_week,'left').reset_index()\n",
    "\n",
    "    df['city_count'] = df.groupby('city_id')['customer_id'].transform('nunique')\n",
    "    df['rest_count'] = df.groupby('restaurant_id')['customer_id'].transform('nunique')\n",
    "    \n",
    "    df['city_mean'] = df.groupby('city_id')['is_returning_customer'].transform('mean')\n",
    "    df['rest_mean'] = df.groupby('restaurant_id')['is_returning_customer'].transform('mean')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search best parameters for the final lightGBM model and features\n",
    "\n",
    "- ROC-AUC: 0.8443 >> 0.846"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T16:37:53.746269Z",
     "start_time": "2020-10-14T16:37:53.736465Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_lgb(df):\n",
    "    \n",
    "    y = df['is_returning_customer']\n",
    "    X = df.drop(columns=['customer_id', 'order_date', 'is_returning_customer',\n",
    "                        'first_order_date', 'index', 'order_date_shift'])    \n",
    "    \n",
    "    clf = lightgbm.LGBMClassifier(random_state=42)\n",
    "    \n",
    "    param_dist = {\n",
    "                    'max_depth': np.arange(3,15,3),\n",
    "                    'min_child_weight': np.arange(1,8,1),\n",
    "                    'colsample_bytree': np.arange(0.3,0.9,0.1),\n",
    "                    'n_estimators': np.arange(100,1000,100),\n",
    "                    'learning_rate': np.arange(0.05,0.3,0.05),\n",
    "                    'num_leaves':  np.arange(10,100,10)\n",
    "             }\n",
    "    \n",
    "    fit_params={\"early_stopping_rounds\":10,\n",
    "               \"eval_metric\" : \"auc\", \n",
    "               \"eval_set\" : [[X, y]]}\n",
    "\n",
    "    grid_search = RandomizedSearchCV(clf, \n",
    "                         param_distributions = param_dist,\n",
    "                         cv = kfold,  \n",
    "                         n_iter = 50,\n",
    "                         verbose = 0, \n",
    "                         n_jobs = -1,\n",
    "                         fit_params=fit_params)\n",
    "    \n",
    "    grid_result = grid_search.fit(X,y)\n",
    "\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_[ 'mean_test_score' ]\n",
    "    stds = grid_result.cv_results_[ 'std_test_score' ]\n",
    "    params = grid_result.cv_results_[ 'params' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T17:19:48.892029Z",
     "start_time": "2020-10-14T16:37:54.397226Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Order data has 786600 rows and 13 columns\n",
      "Label data has 245455 rows and 2 columns\n",
      "The final data has 786600 rows and 14 columns\n",
      "\n",
      "Mem. usage decreased to 42.76 Mb (52.5% reduction)\n",
      "\n",
      "[1]\ttraining's auc: 0.796564\ttraining's binary_logloss: 0.520818\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\ttraining's auc: 0.804678\ttraining's binary_logloss: 0.508937\n",
      "[3]\ttraining's auc: 0.813406\ttraining's binary_logloss: 0.498518\n",
      "[4]\ttraining's auc: 0.822379\ttraining's binary_logloss: 0.489253\n",
      "[5]\ttraining's auc: 0.823235\ttraining's binary_logloss: 0.481081\n",
      "[6]\ttraining's auc: 0.825287\ttraining's binary_logloss: 0.473743\n",
      "[7]\ttraining's auc: 0.826134\ttraining's binary_logloss: 0.467\n",
      "[8]\ttraining's auc: 0.826453\ttraining's binary_logloss: 0.460963\n",
      "[9]\ttraining's auc: 0.826547\ttraining's binary_logloss: 0.455425\n",
      "[10]\ttraining's auc: 0.826811\ttraining's binary_logloss: 0.450358\n",
      "[11]\ttraining's auc: 0.827046\ttraining's binary_logloss: 0.445746\n",
      "[12]\ttraining's auc: 0.827513\ttraining's binary_logloss: 0.441507\n",
      "[13]\ttraining's auc: 0.828552\ttraining's binary_logloss: 0.437745\n",
      "[14]\ttraining's auc: 0.829319\ttraining's binary_logloss: 0.434051\n",
      "[15]\ttraining's auc: 0.829456\ttraining's binary_logloss: 0.430723\n",
      "[16]\ttraining's auc: 0.829398\ttraining's binary_logloss: 0.427657\n",
      "[17]\ttraining's auc: 0.829644\ttraining's binary_logloss: 0.424774\n",
      "[18]\ttraining's auc: 0.830022\ttraining's binary_logloss: 0.422034\n",
      "[19]\ttraining's auc: 0.830172\ttraining's binary_logloss: 0.419499\n",
      "[20]\ttraining's auc: 0.83027\ttraining's binary_logloss: 0.417205\n",
      "[21]\ttraining's auc: 0.830796\ttraining's binary_logloss: 0.414946\n",
      "[22]\ttraining's auc: 0.831283\ttraining's binary_logloss: 0.412788\n",
      "[23]\ttraining's auc: 0.831362\ttraining's binary_logloss: 0.410928\n",
      "[24]\ttraining's auc: 0.831747\ttraining's binary_logloss: 0.409086\n",
      "[25]\ttraining's auc: 0.832181\ttraining's binary_logloss: 0.407307\n",
      "[26]\ttraining's auc: 0.832361\ttraining's binary_logloss: 0.405712\n",
      "[27]\ttraining's auc: 0.832602\ttraining's binary_logloss: 0.40419\n",
      "[28]\ttraining's auc: 0.832842\ttraining's binary_logloss: 0.402751\n",
      "[29]\ttraining's auc: 0.832998\ttraining's binary_logloss: 0.401429\n",
      "[30]\ttraining's auc: 0.833173\ttraining's binary_logloss: 0.400171\n",
      "[31]\ttraining's auc: 0.833585\ttraining's binary_logloss: 0.39899\n",
      "[32]\ttraining's auc: 0.833965\ttraining's binary_logloss: 0.397866\n",
      "[33]\ttraining's auc: 0.834187\ttraining's binary_logloss: 0.396818\n",
      "[34]\ttraining's auc: 0.834385\ttraining's binary_logloss: 0.395785\n",
      "[35]\ttraining's auc: 0.834731\ttraining's binary_logloss: 0.394721\n",
      "[36]\ttraining's auc: 0.834827\ttraining's binary_logloss: 0.393797\n",
      "[37]\ttraining's auc: 0.835072\ttraining's binary_logloss: 0.392866\n",
      "[38]\ttraining's auc: 0.835464\ttraining's binary_logloss: 0.392043\n",
      "[39]\ttraining's auc: 0.835625\ttraining's binary_logloss: 0.391284\n",
      "[40]\ttraining's auc: 0.835787\ttraining's binary_logloss: 0.390505\n",
      "[41]\ttraining's auc: 0.835925\ttraining's binary_logloss: 0.389797\n",
      "[42]\ttraining's auc: 0.836139\ttraining's binary_logloss: 0.389142\n",
      "[43]\ttraining's auc: 0.836341\ttraining's binary_logloss: 0.388482\n",
      "[44]\ttraining's auc: 0.836672\ttraining's binary_logloss: 0.387794\n",
      "[45]\ttraining's auc: 0.836943\ttraining's binary_logloss: 0.387188\n",
      "[46]\ttraining's auc: 0.837105\ttraining's binary_logloss: 0.386604\n",
      "[47]\ttraining's auc: 0.837309\ttraining's binary_logloss: 0.386071\n",
      "[48]\ttraining's auc: 0.837477\ttraining's binary_logloss: 0.385513\n",
      "[49]\ttraining's auc: 0.837602\ttraining's binary_logloss: 0.385026\n",
      "[50]\ttraining's auc: 0.837828\ttraining's binary_logloss: 0.384483\n",
      "[51]\ttraining's auc: 0.838054\ttraining's binary_logloss: 0.384031\n",
      "[52]\ttraining's auc: 0.838163\ttraining's binary_logloss: 0.38356\n",
      "[53]\ttraining's auc: 0.838422\ttraining's binary_logloss: 0.383069\n",
      "[54]\ttraining's auc: 0.838591\ttraining's binary_logloss: 0.382643\n",
      "[55]\ttraining's auc: 0.838798\ttraining's binary_logloss: 0.382279\n",
      "[56]\ttraining's auc: 0.839038\ttraining's binary_logloss: 0.381832\n",
      "[57]\ttraining's auc: 0.839235\ttraining's binary_logloss: 0.38141\n",
      "[58]\ttraining's auc: 0.839415\ttraining's binary_logloss: 0.380995\n",
      "[59]\ttraining's auc: 0.839569\ttraining's binary_logloss: 0.380607\n",
      "[60]\ttraining's auc: 0.839814\ttraining's binary_logloss: 0.380257\n",
      "[61]\ttraining's auc: 0.839929\ttraining's binary_logloss: 0.379939\n",
      "[62]\ttraining's auc: 0.840054\ttraining's binary_logloss: 0.379603\n",
      "[63]\ttraining's auc: 0.840207\ttraining's binary_logloss: 0.379282\n",
      "[64]\ttraining's auc: 0.840332\ttraining's binary_logloss: 0.378958\n",
      "[65]\ttraining's auc: 0.840428\ttraining's binary_logloss: 0.378703\n",
      "[66]\ttraining's auc: 0.840618\ttraining's binary_logloss: 0.378408\n",
      "[67]\ttraining's auc: 0.840725\ttraining's binary_logloss: 0.378167\n",
      "[68]\ttraining's auc: 0.840804\ttraining's binary_logloss: 0.377935\n",
      "[69]\ttraining's auc: 0.84094\ttraining's binary_logloss: 0.377687\n",
      "[70]\ttraining's auc: 0.841079\ttraining's binary_logloss: 0.377442\n",
      "[71]\ttraining's auc: 0.841199\ttraining's binary_logloss: 0.3772\n",
      "[72]\ttraining's auc: 0.841303\ttraining's binary_logloss: 0.376959\n",
      "[73]\ttraining's auc: 0.84144\ttraining's binary_logloss: 0.376718\n",
      "[74]\ttraining's auc: 0.841531\ttraining's binary_logloss: 0.376501\n",
      "[75]\ttraining's auc: 0.841601\ttraining's binary_logloss: 0.376327\n",
      "[76]\ttraining's auc: 0.841693\ttraining's binary_logloss: 0.37613\n",
      "[77]\ttraining's auc: 0.841768\ttraining's binary_logloss: 0.375942\n",
      "[78]\ttraining's auc: 0.841844\ttraining's binary_logloss: 0.37575\n",
      "[79]\ttraining's auc: 0.841931\ttraining's binary_logloss: 0.375572\n",
      "[80]\ttraining's auc: 0.842017\ttraining's binary_logloss: 0.375412\n",
      "[81]\ttraining's auc: 0.842147\ttraining's binary_logloss: 0.375267\n",
      "[82]\ttraining's auc: 0.84222\ttraining's binary_logloss: 0.375102\n",
      "[83]\ttraining's auc: 0.842298\ttraining's binary_logloss: 0.374954\n",
      "[84]\ttraining's auc: 0.84238\ttraining's binary_logloss: 0.374792\n",
      "[85]\ttraining's auc: 0.84251\ttraining's binary_logloss: 0.374633\n",
      "[86]\ttraining's auc: 0.84258\ttraining's binary_logloss: 0.374481\n",
      "[87]\ttraining's auc: 0.842682\ttraining's binary_logloss: 0.374366\n",
      "[88]\ttraining's auc: 0.842753\ttraining's binary_logloss: 0.374262\n",
      "[89]\ttraining's auc: 0.842857\ttraining's binary_logloss: 0.374118\n",
      "[90]\ttraining's auc: 0.842909\ttraining's binary_logloss: 0.373993\n",
      "[91]\ttraining's auc: 0.842971\ttraining's binary_logloss: 0.373883\n",
      "[92]\ttraining's auc: 0.843021\ttraining's binary_logloss: 0.373768\n",
      "[93]\ttraining's auc: 0.843079\ttraining's binary_logloss: 0.373655\n",
      "[94]\ttraining's auc: 0.843138\ttraining's binary_logloss: 0.373536\n",
      "[95]\ttraining's auc: 0.843192\ttraining's binary_logloss: 0.373402\n",
      "[96]\ttraining's auc: 0.843265\ttraining's binary_logloss: 0.373316\n",
      "[97]\ttraining's auc: 0.843317\ttraining's binary_logloss: 0.373203\n",
      "[98]\ttraining's auc: 0.843357\ttraining's binary_logloss: 0.373105\n",
      "[99]\ttraining's auc: 0.843409\ttraining's binary_logloss: 0.372993\n",
      "[100]\ttraining's auc: 0.843475\ttraining's binary_logloss: 0.372904\n",
      "[101]\ttraining's auc: 0.843523\ttraining's binary_logloss: 0.372802\n",
      "[102]\ttraining's auc: 0.843569\ttraining's binary_logloss: 0.372705\n",
      "[103]\ttraining's auc: 0.843626\ttraining's binary_logloss: 0.372611\n",
      "[104]\ttraining's auc: 0.843671\ttraining's binary_logloss: 0.372528\n",
      "[105]\ttraining's auc: 0.843741\ttraining's binary_logloss: 0.372446\n",
      "[106]\ttraining's auc: 0.843806\ttraining's binary_logloss: 0.372361\n",
      "[107]\ttraining's auc: 0.84384\ttraining's binary_logloss: 0.372284\n",
      "[108]\ttraining's auc: 0.843899\ttraining's binary_logloss: 0.372206\n",
      "[109]\ttraining's auc: 0.843946\ttraining's binary_logloss: 0.37214\n",
      "[110]\ttraining's auc: 0.843985\ttraining's binary_logloss: 0.372056\n",
      "[111]\ttraining's auc: 0.844032\ttraining's binary_logloss: 0.371981\n",
      "[112]\ttraining's auc: 0.844057\ttraining's binary_logloss: 0.371919\n",
      "[113]\ttraining's auc: 0.844107\ttraining's binary_logloss: 0.371845\n",
      "[114]\ttraining's auc: 0.844177\ttraining's binary_logloss: 0.371776\n",
      "[115]\ttraining's auc: 0.844209\ttraining's binary_logloss: 0.371704\n",
      "[116]\ttraining's auc: 0.844254\ttraining's binary_logloss: 0.371644\n",
      "[117]\ttraining's auc: 0.844293\ttraining's binary_logloss: 0.371564\n",
      "[118]\ttraining's auc: 0.844328\ttraining's binary_logloss: 0.371507\n",
      "[119]\ttraining's auc: 0.844384\ttraining's binary_logloss: 0.371441\n",
      "[120]\ttraining's auc: 0.844439\ttraining's binary_logloss: 0.371355\n",
      "[121]\ttraining's auc: 0.844473\ttraining's binary_logloss: 0.371299\n",
      "[122]\ttraining's auc: 0.844503\ttraining's binary_logloss: 0.371241\n",
      "[123]\ttraining's auc: 0.844556\ttraining's binary_logloss: 0.371184\n",
      "[124]\ttraining's auc: 0.844591\ttraining's binary_logloss: 0.371113\n",
      "[125]\ttraining's auc: 0.844625\ttraining's binary_logloss: 0.37106\n",
      "[126]\ttraining's auc: 0.844663\ttraining's binary_logloss: 0.371008\n",
      "[127]\ttraining's auc: 0.844697\ttraining's binary_logloss: 0.370958\n",
      "[128]\ttraining's auc: 0.844729\ttraining's binary_logloss: 0.370912\n",
      "[129]\ttraining's auc: 0.844757\ttraining's binary_logloss: 0.370856\n",
      "[130]\ttraining's auc: 0.844796\ttraining's binary_logloss: 0.370806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[131]\ttraining's auc: 0.844829\ttraining's binary_logloss: 0.370759\n",
      "[132]\ttraining's auc: 0.844871\ttraining's binary_logloss: 0.370698\n",
      "[133]\ttraining's auc: 0.844909\ttraining's binary_logloss: 0.37065\n",
      "[134]\ttraining's auc: 0.844935\ttraining's binary_logloss: 0.370604\n",
      "[135]\ttraining's auc: 0.844985\ttraining's binary_logloss: 0.370558\n",
      "[136]\ttraining's auc: 0.845006\ttraining's binary_logloss: 0.370516\n",
      "[137]\ttraining's auc: 0.845035\ttraining's binary_logloss: 0.370478\n",
      "[138]\ttraining's auc: 0.845064\ttraining's binary_logloss: 0.370431\n",
      "[139]\ttraining's auc: 0.845089\ttraining's binary_logloss: 0.370381\n",
      "[140]\ttraining's auc: 0.845107\ttraining's binary_logloss: 0.370337\n",
      "[141]\ttraining's auc: 0.845134\ttraining's binary_logloss: 0.370298\n",
      "[142]\ttraining's auc: 0.845164\ttraining's binary_logloss: 0.370254\n",
      "[143]\ttraining's auc: 0.845195\ttraining's binary_logloss: 0.370202\n",
      "[144]\ttraining's auc: 0.845236\ttraining's binary_logloss: 0.37016\n",
      "[145]\ttraining's auc: 0.845266\ttraining's binary_logloss: 0.370119\n",
      "[146]\ttraining's auc: 0.845297\ttraining's binary_logloss: 0.370067\n",
      "[147]\ttraining's auc: 0.845351\ttraining's binary_logloss: 0.369988\n",
      "[148]\ttraining's auc: 0.845377\ttraining's binary_logloss: 0.369951\n",
      "[149]\ttraining's auc: 0.8454\ttraining's binary_logloss: 0.369909\n",
      "[150]\ttraining's auc: 0.845419\ttraining's binary_logloss: 0.369867\n",
      "[151]\ttraining's auc: 0.845463\ttraining's binary_logloss: 0.369817\n",
      "[152]\ttraining's auc: 0.845493\ttraining's binary_logloss: 0.369774\n",
      "[153]\ttraining's auc: 0.845517\ttraining's binary_logloss: 0.369741\n",
      "[154]\ttraining's auc: 0.845556\ttraining's binary_logloss: 0.369706\n",
      "[155]\ttraining's auc: 0.845577\ttraining's binary_logloss: 0.36967\n",
      "[156]\ttraining's auc: 0.845603\ttraining's binary_logloss: 0.369634\n",
      "[157]\ttraining's auc: 0.845629\ttraining's binary_logloss: 0.369593\n",
      "[158]\ttraining's auc: 0.845663\ttraining's binary_logloss: 0.36956\n",
      "[159]\ttraining's auc: 0.84569\ttraining's binary_logloss: 0.36953\n",
      "[160]\ttraining's auc: 0.845722\ttraining's binary_logloss: 0.369495\n",
      "[161]\ttraining's auc: 0.845748\ttraining's binary_logloss: 0.369457\n",
      "[162]\ttraining's auc: 0.845764\ttraining's binary_logloss: 0.369427\n",
      "[163]\ttraining's auc: 0.845784\ttraining's binary_logloss: 0.369398\n",
      "[164]\ttraining's auc: 0.845806\ttraining's binary_logloss: 0.369369\n",
      "[165]\ttraining's auc: 0.845847\ttraining's binary_logloss: 0.369328\n",
      "[166]\ttraining's auc: 0.845862\ttraining's binary_logloss: 0.369294\n",
      "[167]\ttraining's auc: 0.845883\ttraining's binary_logloss: 0.369257\n",
      "[168]\ttraining's auc: 0.845893\ttraining's binary_logloss: 0.369229\n",
      "[169]\ttraining's auc: 0.845919\ttraining's binary_logloss: 0.369179\n",
      "[170]\ttraining's auc: 0.845938\ttraining's binary_logloss: 0.369149\n",
      "[171]\ttraining's auc: 0.845962\ttraining's binary_logloss: 0.369115\n",
      "[172]\ttraining's auc: 0.845991\ttraining's binary_logloss: 0.36909\n",
      "[173]\ttraining's auc: 0.846005\ttraining's binary_logloss: 0.369065\n",
      "[174]\ttraining's auc: 0.846027\ttraining's binary_logloss: 0.369033\n",
      "[175]\ttraining's auc: 0.846049\ttraining's binary_logloss: 0.369001\n",
      "[176]\ttraining's auc: 0.846066\ttraining's binary_logloss: 0.368961\n",
      "[177]\ttraining's auc: 0.846081\ttraining's binary_logloss: 0.368934\n",
      "[178]\ttraining's auc: 0.846093\ttraining's binary_logloss: 0.368908\n",
      "[179]\ttraining's auc: 0.846125\ttraining's binary_logloss: 0.368877\n",
      "[180]\ttraining's auc: 0.84615\ttraining's binary_logloss: 0.368848\n",
      "[181]\ttraining's auc: 0.846179\ttraining's binary_logloss: 0.368817\n",
      "[182]\ttraining's auc: 0.846196\ttraining's binary_logloss: 0.368792\n",
      "[183]\ttraining's auc: 0.846218\ttraining's binary_logloss: 0.368763\n",
      "[184]\ttraining's auc: 0.846231\ttraining's binary_logloss: 0.36874\n",
      "[185]\ttraining's auc: 0.846244\ttraining's binary_logloss: 0.368717\n",
      "[186]\ttraining's auc: 0.846271\ttraining's binary_logloss: 0.368691\n",
      "[187]\ttraining's auc: 0.846278\ttraining's binary_logloss: 0.368671\n",
      "[188]\ttraining's auc: 0.846304\ttraining's binary_logloss: 0.368644\n",
      "[189]\ttraining's auc: 0.846325\ttraining's binary_logloss: 0.368608\n",
      "[190]\ttraining's auc: 0.846343\ttraining's binary_logloss: 0.368587\n",
      "[191]\ttraining's auc: 0.846359\ttraining's binary_logloss: 0.368567\n",
      "[192]\ttraining's auc: 0.84639\ttraining's binary_logloss: 0.368539\n",
      "[193]\ttraining's auc: 0.8464\ttraining's binary_logloss: 0.368515\n",
      "[194]\ttraining's auc: 0.846425\ttraining's binary_logloss: 0.368483\n",
      "[195]\ttraining's auc: 0.846435\ttraining's binary_logloss: 0.36846\n",
      "[196]\ttraining's auc: 0.846447\ttraining's binary_logloss: 0.368438\n",
      "[197]\ttraining's auc: 0.846469\ttraining's binary_logloss: 0.368412\n",
      "[198]\ttraining's auc: 0.846494\ttraining's binary_logloss: 0.368384\n",
      "[199]\ttraining's auc: 0.846503\ttraining's binary_logloss: 0.368365\n",
      "[200]\ttraining's auc: 0.84652\ttraining's binary_logloss: 0.36834\n",
      "[201]\ttraining's auc: 0.846546\ttraining's binary_logloss: 0.368309\n",
      "[202]\ttraining's auc: 0.84656\ttraining's binary_logloss: 0.368286\n",
      "[203]\ttraining's auc: 0.846578\ttraining's binary_logloss: 0.368262\n",
      "[204]\ttraining's auc: 0.846594\ttraining's binary_logloss: 0.368239\n",
      "[205]\ttraining's auc: 0.846605\ttraining's binary_logloss: 0.36822\n",
      "[206]\ttraining's auc: 0.846621\ttraining's binary_logloss: 0.368201\n",
      "[207]\ttraining's auc: 0.84663\ttraining's binary_logloss: 0.368182\n",
      "[208]\ttraining's auc: 0.846643\ttraining's binary_logloss: 0.368161\n",
      "[209]\ttraining's auc: 0.846661\ttraining's binary_logloss: 0.368137\n",
      "[210]\ttraining's auc: 0.846677\ttraining's binary_logloss: 0.368121\n",
      "[211]\ttraining's auc: 0.846688\ttraining's binary_logloss: 0.368102\n",
      "[212]\ttraining's auc: 0.846707\ttraining's binary_logloss: 0.368081\n",
      "[213]\ttraining's auc: 0.846717\ttraining's binary_logloss: 0.368059\n",
      "[214]\ttraining's auc: 0.846722\ttraining's binary_logloss: 0.368038\n",
      "[215]\ttraining's auc: 0.846738\ttraining's binary_logloss: 0.368017\n",
      "[216]\ttraining's auc: 0.846758\ttraining's binary_logloss: 0.36799\n",
      "[217]\ttraining's auc: 0.846764\ttraining's binary_logloss: 0.367975\n",
      "[218]\ttraining's auc: 0.84678\ttraining's binary_logloss: 0.367957\n",
      "[219]\ttraining's auc: 0.846794\ttraining's binary_logloss: 0.367931\n",
      "[220]\ttraining's auc: 0.846804\ttraining's binary_logloss: 0.367913\n",
      "[221]\ttraining's auc: 0.846818\ttraining's binary_logloss: 0.367894\n",
      "[222]\ttraining's auc: 0.846834\ttraining's binary_logloss: 0.367872\n",
      "[223]\ttraining's auc: 0.84685\ttraining's binary_logloss: 0.367855\n",
      "[224]\ttraining's auc: 0.846873\ttraining's binary_logloss: 0.367836\n",
      "[225]\ttraining's auc: 0.846889\ttraining's binary_logloss: 0.367817\n",
      "[226]\ttraining's auc: 0.846902\ttraining's binary_logloss: 0.367798\n",
      "[227]\ttraining's auc: 0.846911\ttraining's binary_logloss: 0.367771\n",
      "[228]\ttraining's auc: 0.846919\ttraining's binary_logloss: 0.367755\n",
      "[229]\ttraining's auc: 0.846924\ttraining's binary_logloss: 0.367733\n",
      "[230]\ttraining's auc: 0.846947\ttraining's binary_logloss: 0.367704\n",
      "[231]\ttraining's auc: 0.846954\ttraining's binary_logloss: 0.367689\n",
      "[232]\ttraining's auc: 0.846969\ttraining's binary_logloss: 0.367672\n",
      "[233]\ttraining's auc: 0.846972\ttraining's binary_logloss: 0.367659\n",
      "[234]\ttraining's auc: 0.847002\ttraining's binary_logloss: 0.367626\n",
      "[235]\ttraining's auc: 0.847017\ttraining's binary_logloss: 0.36761\n",
      "[236]\ttraining's auc: 0.847035\ttraining's binary_logloss: 0.367591\n",
      "[237]\ttraining's auc: 0.847044\ttraining's binary_logloss: 0.367571\n",
      "[238]\ttraining's auc: 0.84706\ttraining's binary_logloss: 0.36754\n",
      "[239]\ttraining's auc: 0.847075\ttraining's binary_logloss: 0.367524\n",
      "[240]\ttraining's auc: 0.847087\ttraining's binary_logloss: 0.367509\n",
      "[241]\ttraining's auc: 0.847115\ttraining's binary_logloss: 0.367483\n",
      "[242]\ttraining's auc: 0.847139\ttraining's binary_logloss: 0.367451\n",
      "[243]\ttraining's auc: 0.847149\ttraining's binary_logloss: 0.36743\n",
      "[244]\ttraining's auc: 0.847163\ttraining's binary_logloss: 0.367401\n",
      "[245]\ttraining's auc: 0.847186\ttraining's binary_logloss: 0.367383\n",
      "[246]\ttraining's auc: 0.8472\ttraining's binary_logloss: 0.367362\n",
      "[247]\ttraining's auc: 0.847211\ttraining's binary_logloss: 0.367342\n",
      "[248]\ttraining's auc: 0.847218\ttraining's binary_logloss: 0.367326\n",
      "[249]\ttraining's auc: 0.847235\ttraining's binary_logloss: 0.367312\n",
      "[250]\ttraining's auc: 0.847252\ttraining's binary_logloss: 0.367293\n",
      "[251]\ttraining's auc: 0.84727\ttraining's binary_logloss: 0.367274\n",
      "[252]\ttraining's auc: 0.847289\ttraining's binary_logloss: 0.367258\n",
      "[253]\ttraining's auc: 0.847298\ttraining's binary_logloss: 0.367242\n",
      "[254]\ttraining's auc: 0.847306\ttraining's binary_logloss: 0.367225\n",
      "[255]\ttraining's auc: 0.847321\ttraining's binary_logloss: 0.367206\n",
      "[256]\ttraining's auc: 0.847339\ttraining's binary_logloss: 0.367192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[257]\ttraining's auc: 0.847345\ttraining's binary_logloss: 0.367177\n",
      "[258]\ttraining's auc: 0.847352\ttraining's binary_logloss: 0.367162\n",
      "[259]\ttraining's auc: 0.847361\ttraining's binary_logloss: 0.367147\n",
      "[260]\ttraining's auc: 0.847376\ttraining's binary_logloss: 0.367129\n",
      "[261]\ttraining's auc: 0.847397\ttraining's binary_logloss: 0.36711\n",
      "[262]\ttraining's auc: 0.847414\ttraining's binary_logloss: 0.367085\n",
      "[263]\ttraining's auc: 0.847438\ttraining's binary_logloss: 0.367072\n",
      "[264]\ttraining's auc: 0.847445\ttraining's binary_logloss: 0.367054\n",
      "[265]\ttraining's auc: 0.847455\ttraining's binary_logloss: 0.367039\n",
      "[266]\ttraining's auc: 0.847478\ttraining's binary_logloss: 0.367019\n",
      "[267]\ttraining's auc: 0.847497\ttraining's binary_logloss: 0.366996\n",
      "[268]\ttraining's auc: 0.847506\ttraining's binary_logloss: 0.36698\n",
      "[269]\ttraining's auc: 0.847515\ttraining's binary_logloss: 0.366964\n",
      "[270]\ttraining's auc: 0.847529\ttraining's binary_logloss: 0.366947\n",
      "[271]\ttraining's auc: 0.847541\ttraining's binary_logloss: 0.366931\n",
      "[272]\ttraining's auc: 0.847563\ttraining's binary_logloss: 0.366916\n",
      "[273]\ttraining's auc: 0.847573\ttraining's binary_logloss: 0.3669\n",
      "[274]\ttraining's auc: 0.847582\ttraining's binary_logloss: 0.366887\n",
      "[275]\ttraining's auc: 0.847595\ttraining's binary_logloss: 0.366862\n",
      "[276]\ttraining's auc: 0.847603\ttraining's binary_logloss: 0.366845\n",
      "[277]\ttraining's auc: 0.847625\ttraining's binary_logloss: 0.36683\n",
      "[278]\ttraining's auc: 0.84763\ttraining's binary_logloss: 0.366816\n",
      "[279]\ttraining's auc: 0.847638\ttraining's binary_logloss: 0.366801\n",
      "[280]\ttraining's auc: 0.847658\ttraining's binary_logloss: 0.366777\n",
      "[281]\ttraining's auc: 0.847677\ttraining's binary_logloss: 0.366764\n",
      "[282]\ttraining's auc: 0.847683\ttraining's binary_logloss: 0.36675\n",
      "[283]\ttraining's auc: 0.84769\ttraining's binary_logloss: 0.366733\n",
      "[284]\ttraining's auc: 0.847712\ttraining's binary_logloss: 0.366714\n",
      "[285]\ttraining's auc: 0.847726\ttraining's binary_logloss: 0.366696\n",
      "[286]\ttraining's auc: 0.84775\ttraining's binary_logloss: 0.366675\n",
      "[287]\ttraining's auc: 0.847762\ttraining's binary_logloss: 0.366657\n",
      "[288]\ttraining's auc: 0.847779\ttraining's binary_logloss: 0.366642\n",
      "[289]\ttraining's auc: 0.847783\ttraining's binary_logloss: 0.366629\n",
      "[290]\ttraining's auc: 0.847788\ttraining's binary_logloss: 0.366614\n",
      "[291]\ttraining's auc: 0.847796\ttraining's binary_logloss: 0.366598\n",
      "[292]\ttraining's auc: 0.847801\ttraining's binary_logloss: 0.366584\n",
      "[293]\ttraining's auc: 0.84782\ttraining's binary_logloss: 0.366565\n",
      "[294]\ttraining's auc: 0.847834\ttraining's binary_logloss: 0.366545\n",
      "[295]\ttraining's auc: 0.847841\ttraining's binary_logloss: 0.36653\n",
      "[296]\ttraining's auc: 0.84786\ttraining's binary_logloss: 0.366515\n",
      "[297]\ttraining's auc: 0.847869\ttraining's binary_logloss: 0.366499\n",
      "[298]\ttraining's auc: 0.847878\ttraining's binary_logloss: 0.366485\n",
      "[299]\ttraining's auc: 0.847897\ttraining's binary_logloss: 0.366466\n",
      "[300]\ttraining's auc: 0.847917\ttraining's binary_logloss: 0.366437\n",
      "[301]\ttraining's auc: 0.847925\ttraining's binary_logloss: 0.366422\n",
      "[302]\ttraining's auc: 0.847928\ttraining's binary_logloss: 0.366409\n",
      "[303]\ttraining's auc: 0.847937\ttraining's binary_logloss: 0.366395\n",
      "[304]\ttraining's auc: 0.84795\ttraining's binary_logloss: 0.366376\n",
      "[305]\ttraining's auc: 0.847969\ttraining's binary_logloss: 0.366362\n",
      "[306]\ttraining's auc: 0.847974\ttraining's binary_logloss: 0.366348\n",
      "[307]\ttraining's auc: 0.847989\ttraining's binary_logloss: 0.366331\n",
      "[308]\ttraining's auc: 0.847996\ttraining's binary_logloss: 0.366322\n",
      "[309]\ttraining's auc: 0.848007\ttraining's binary_logloss: 0.366303\n",
      "[310]\ttraining's auc: 0.848017\ttraining's binary_logloss: 0.366289\n",
      "[311]\ttraining's auc: 0.848023\ttraining's binary_logloss: 0.366274\n",
      "[312]\ttraining's auc: 0.848035\ttraining's binary_logloss: 0.366251\n",
      "[313]\ttraining's auc: 0.848038\ttraining's binary_logloss: 0.366239\n",
      "[314]\ttraining's auc: 0.848055\ttraining's binary_logloss: 0.366222\n",
      "[315]\ttraining's auc: 0.848067\ttraining's binary_logloss: 0.366201\n",
      "[316]\ttraining's auc: 0.848087\ttraining's binary_logloss: 0.366185\n",
      "[317]\ttraining's auc: 0.848094\ttraining's binary_logloss: 0.366169\n",
      "[318]\ttraining's auc: 0.848111\ttraining's binary_logloss: 0.366151\n",
      "[319]\ttraining's auc: 0.848132\ttraining's binary_logloss: 0.366139\n",
      "[320]\ttraining's auc: 0.848135\ttraining's binary_logloss: 0.366125\n",
      "[321]\ttraining's auc: 0.848152\ttraining's binary_logloss: 0.366107\n",
      "[322]\ttraining's auc: 0.84816\ttraining's binary_logloss: 0.366093\n",
      "[323]\ttraining's auc: 0.848166\ttraining's binary_logloss: 0.366077\n",
      "[324]\ttraining's auc: 0.848182\ttraining's binary_logloss: 0.366054\n",
      "[325]\ttraining's auc: 0.848197\ttraining's binary_logloss: 0.366033\n",
      "[326]\ttraining's auc: 0.848213\ttraining's binary_logloss: 0.366011\n",
      "[327]\ttraining's auc: 0.848219\ttraining's binary_logloss: 0.365994\n",
      "[328]\ttraining's auc: 0.848224\ttraining's binary_logloss: 0.365978\n",
      "[329]\ttraining's auc: 0.848244\ttraining's binary_logloss: 0.365963\n",
      "[330]\ttraining's auc: 0.848262\ttraining's binary_logloss: 0.365952\n",
      "[331]\ttraining's auc: 0.848275\ttraining's binary_logloss: 0.36594\n",
      "[332]\ttraining's auc: 0.848289\ttraining's binary_logloss: 0.365925\n",
      "[333]\ttraining's auc: 0.848304\ttraining's binary_logloss: 0.365911\n",
      "[334]\ttraining's auc: 0.848309\ttraining's binary_logloss: 0.365897\n",
      "[335]\ttraining's auc: 0.848339\ttraining's binary_logloss: 0.36588\n",
      "[336]\ttraining's auc: 0.848352\ttraining's binary_logloss: 0.365869\n",
      "[337]\ttraining's auc: 0.848362\ttraining's binary_logloss: 0.365853\n",
      "[338]\ttraining's auc: 0.848386\ttraining's binary_logloss: 0.365829\n",
      "[339]\ttraining's auc: 0.848389\ttraining's binary_logloss: 0.365817\n",
      "[340]\ttraining's auc: 0.848404\ttraining's binary_logloss: 0.365803\n",
      "[341]\ttraining's auc: 0.84842\ttraining's binary_logloss: 0.36579\n",
      "[342]\ttraining's auc: 0.848432\ttraining's binary_logloss: 0.365778\n",
      "[343]\ttraining's auc: 0.84845\ttraining's binary_logloss: 0.36576\n",
      "[344]\ttraining's auc: 0.848457\ttraining's binary_logloss: 0.365746\n",
      "[345]\ttraining's auc: 0.848462\ttraining's binary_logloss: 0.365732\n",
      "[346]\ttraining's auc: 0.848488\ttraining's binary_logloss: 0.365716\n",
      "[347]\ttraining's auc: 0.848505\ttraining's binary_logloss: 0.365703\n",
      "[348]\ttraining's auc: 0.848508\ttraining's binary_logloss: 0.365691\n",
      "[349]\ttraining's auc: 0.848522\ttraining's binary_logloss: 0.36568\n",
      "[350]\ttraining's auc: 0.848525\ttraining's binary_logloss: 0.365665\n",
      "[351]\ttraining's auc: 0.848544\ttraining's binary_logloss: 0.365647\n",
      "[352]\ttraining's auc: 0.848552\ttraining's binary_logloss: 0.365626\n",
      "[353]\ttraining's auc: 0.848567\ttraining's binary_logloss: 0.365613\n",
      "[354]\ttraining's auc: 0.848587\ttraining's binary_logloss: 0.365597\n",
      "[355]\ttraining's auc: 0.848603\ttraining's binary_logloss: 0.365575\n",
      "[356]\ttraining's auc: 0.848611\ttraining's binary_logloss: 0.36556\n",
      "[357]\ttraining's auc: 0.848614\ttraining's binary_logloss: 0.365549\n",
      "[358]\ttraining's auc: 0.848623\ttraining's binary_logloss: 0.365533\n",
      "[359]\ttraining's auc: 0.848635\ttraining's binary_logloss: 0.365515\n",
      "[360]\ttraining's auc: 0.848657\ttraining's binary_logloss: 0.365497\n",
      "[361]\ttraining's auc: 0.848663\ttraining's binary_logloss: 0.36549\n",
      "[362]\ttraining's auc: 0.84867\ttraining's binary_logloss: 0.365477\n",
      "[363]\ttraining's auc: 0.848699\ttraining's binary_logloss: 0.365455\n",
      "[364]\ttraining's auc: 0.848722\ttraining's binary_logloss: 0.365437\n",
      "[365]\ttraining's auc: 0.848729\ttraining's binary_logloss: 0.365424\n",
      "[366]\ttraining's auc: 0.848735\ttraining's binary_logloss: 0.365413\n",
      "[367]\ttraining's auc: 0.84874\ttraining's binary_logloss: 0.365401\n",
      "[368]\ttraining's auc: 0.848744\ttraining's binary_logloss: 0.365391\n",
      "[369]\ttraining's auc: 0.848759\ttraining's binary_logloss: 0.365376\n",
      "[370]\ttraining's auc: 0.848785\ttraining's binary_logloss: 0.36536\n",
      "[371]\ttraining's auc: 0.848798\ttraining's binary_logloss: 0.365347\n",
      "[372]\ttraining's auc: 0.848804\ttraining's binary_logloss: 0.365334\n",
      "[373]\ttraining's auc: 0.848817\ttraining's binary_logloss: 0.36532\n",
      "[374]\ttraining's auc: 0.848823\ttraining's binary_logloss: 0.365306\n",
      "[375]\ttraining's auc: 0.848838\ttraining's binary_logloss: 0.365285\n",
      "[376]\ttraining's auc: 0.848852\ttraining's binary_logloss: 0.365271\n",
      "[377]\ttraining's auc: 0.84886\ttraining's binary_logloss: 0.365256\n",
      "[378]\ttraining's auc: 0.848884\ttraining's binary_logloss: 0.365238\n",
      "[379]\ttraining's auc: 0.84889\ttraining's binary_logloss: 0.365225\n",
      "[380]\ttraining's auc: 0.848894\ttraining's binary_logloss: 0.365213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[381]\ttraining's auc: 0.848899\ttraining's binary_logloss: 0.365199\n",
      "[382]\ttraining's auc: 0.848917\ttraining's binary_logloss: 0.365176\n",
      "[383]\ttraining's auc: 0.848922\ttraining's binary_logloss: 0.365165\n",
      "[384]\ttraining's auc: 0.848945\ttraining's binary_logloss: 0.365149\n",
      "[385]\ttraining's auc: 0.848962\ttraining's binary_logloss: 0.365138\n",
      "[386]\ttraining's auc: 0.848965\ttraining's binary_logloss: 0.365129\n",
      "[387]\ttraining's auc: 0.848969\ttraining's binary_logloss: 0.365114\n",
      "[388]\ttraining's auc: 0.848994\ttraining's binary_logloss: 0.365095\n",
      "[389]\ttraining's auc: 0.849018\ttraining's binary_logloss: 0.365081\n",
      "[390]\ttraining's auc: 0.84903\ttraining's binary_logloss: 0.365068\n",
      "[391]\ttraining's auc: 0.849043\ttraining's binary_logloss: 0.365053\n",
      "[392]\ttraining's auc: 0.849058\ttraining's binary_logloss: 0.365036\n",
      "[393]\ttraining's auc: 0.84908\ttraining's binary_logloss: 0.365019\n",
      "[394]\ttraining's auc: 0.849093\ttraining's binary_logloss: 0.365004\n",
      "[395]\ttraining's auc: 0.849108\ttraining's binary_logloss: 0.364988\n",
      "[396]\ttraining's auc: 0.849126\ttraining's binary_logloss: 0.364972\n",
      "[397]\ttraining's auc: 0.849131\ttraining's binary_logloss: 0.364962\n",
      "[398]\ttraining's auc: 0.849148\ttraining's binary_logloss: 0.36494\n",
      "[399]\ttraining's auc: 0.849151\ttraining's binary_logloss: 0.364928\n",
      "[400]\ttraining's auc: 0.849155\ttraining's binary_logloss: 0.364922\n",
      "[401]\ttraining's auc: 0.849159\ttraining's binary_logloss: 0.364911\n",
      "[402]\ttraining's auc: 0.849166\ttraining's binary_logloss: 0.364896\n",
      "[403]\ttraining's auc: 0.849171\ttraining's binary_logloss: 0.364883\n",
      "[404]\ttraining's auc: 0.849178\ttraining's binary_logloss: 0.364873\n",
      "[405]\ttraining's auc: 0.849203\ttraining's binary_logloss: 0.364857\n",
      "[406]\ttraining's auc: 0.849218\ttraining's binary_logloss: 0.364844\n",
      "[407]\ttraining's auc: 0.849228\ttraining's binary_logloss: 0.364829\n",
      "[408]\ttraining's auc: 0.849249\ttraining's binary_logloss: 0.364809\n",
      "[409]\ttraining's auc: 0.849256\ttraining's binary_logloss: 0.364797\n",
      "[410]\ttraining's auc: 0.849268\ttraining's binary_logloss: 0.364785\n",
      "[411]\ttraining's auc: 0.849269\ttraining's binary_logloss: 0.364777\n",
      "[412]\ttraining's auc: 0.849278\ttraining's binary_logloss: 0.36476\n",
      "[413]\ttraining's auc: 0.849288\ttraining's binary_logloss: 0.364747\n",
      "[414]\ttraining's auc: 0.849296\ttraining's binary_logloss: 0.364733\n",
      "[415]\ttraining's auc: 0.84931\ttraining's binary_logloss: 0.364722\n",
      "[416]\ttraining's auc: 0.849325\ttraining's binary_logloss: 0.364707\n",
      "[417]\ttraining's auc: 0.849336\ttraining's binary_logloss: 0.364691\n",
      "[418]\ttraining's auc: 0.849341\ttraining's binary_logloss: 0.364679\n",
      "[419]\ttraining's auc: 0.84935\ttraining's binary_logloss: 0.36466\n",
      "[420]\ttraining's auc: 0.849363\ttraining's binary_logloss: 0.364644\n",
      "[421]\ttraining's auc: 0.849367\ttraining's binary_logloss: 0.36463\n",
      "[422]\ttraining's auc: 0.849391\ttraining's binary_logloss: 0.364616\n",
      "[423]\ttraining's auc: 0.849397\ttraining's binary_logloss: 0.364603\n",
      "[424]\ttraining's auc: 0.849404\ttraining's binary_logloss: 0.364593\n",
      "[425]\ttraining's auc: 0.849417\ttraining's binary_logloss: 0.364583\n",
      "[426]\ttraining's auc: 0.849427\ttraining's binary_logloss: 0.364568\n",
      "[427]\ttraining's auc: 0.849453\ttraining's binary_logloss: 0.364552\n",
      "[428]\ttraining's auc: 0.849471\ttraining's binary_logloss: 0.364539\n",
      "[429]\ttraining's auc: 0.849476\ttraining's binary_logloss: 0.364527\n",
      "[430]\ttraining's auc: 0.849483\ttraining's binary_logloss: 0.364517\n",
      "[431]\ttraining's auc: 0.849504\ttraining's binary_logloss: 0.364502\n",
      "[432]\ttraining's auc: 0.849513\ttraining's binary_logloss: 0.364488\n",
      "[433]\ttraining's auc: 0.849519\ttraining's binary_logloss: 0.364476\n",
      "[434]\ttraining's auc: 0.849523\ttraining's binary_logloss: 0.364463\n",
      "[435]\ttraining's auc: 0.849532\ttraining's binary_logloss: 0.364446\n",
      "[436]\ttraining's auc: 0.849552\ttraining's binary_logloss: 0.364434\n",
      "[437]\ttraining's auc: 0.849554\ttraining's binary_logloss: 0.364426\n",
      "[438]\ttraining's auc: 0.849563\ttraining's binary_logloss: 0.364419\n",
      "[439]\ttraining's auc: 0.84957\ttraining's binary_logloss: 0.364407\n",
      "[440]\ttraining's auc: 0.849579\ttraining's binary_logloss: 0.364392\n",
      "[441]\ttraining's auc: 0.849583\ttraining's binary_logloss: 0.364383\n",
      "[442]\ttraining's auc: 0.84959\ttraining's binary_logloss: 0.36437\n",
      "[443]\ttraining's auc: 0.849595\ttraining's binary_logloss: 0.364359\n",
      "[444]\ttraining's auc: 0.849601\ttraining's binary_logloss: 0.364344\n",
      "[445]\ttraining's auc: 0.849608\ttraining's binary_logloss: 0.364326\n",
      "[446]\ttraining's auc: 0.849619\ttraining's binary_logloss: 0.364316\n",
      "[447]\ttraining's auc: 0.849629\ttraining's binary_logloss: 0.364301\n",
      "[448]\ttraining's auc: 0.849632\ttraining's binary_logloss: 0.364286\n",
      "[449]\ttraining's auc: 0.849643\ttraining's binary_logloss: 0.364271\n",
      "[450]\ttraining's auc: 0.84965\ttraining's binary_logloss: 0.364259\n",
      "[451]\ttraining's auc: 0.849657\ttraining's binary_logloss: 0.364245\n",
      "[452]\ttraining's auc: 0.849673\ttraining's binary_logloss: 0.364229\n",
      "[453]\ttraining's auc: 0.849689\ttraining's binary_logloss: 0.36421\n",
      "[454]\ttraining's auc: 0.849701\ttraining's binary_logloss: 0.364197\n",
      "[455]\ttraining's auc: 0.849713\ttraining's binary_logloss: 0.364181\n",
      "[456]\ttraining's auc: 0.849719\ttraining's binary_logloss: 0.364168\n",
      "[457]\ttraining's auc: 0.849737\ttraining's binary_logloss: 0.364153\n",
      "[458]\ttraining's auc: 0.849755\ttraining's binary_logloss: 0.36414\n",
      "[459]\ttraining's auc: 0.849769\ttraining's binary_logloss: 0.364125\n",
      "[460]\ttraining's auc: 0.84977\ttraining's binary_logloss: 0.364114\n",
      "[461]\ttraining's auc: 0.849775\ttraining's binary_logloss: 0.364104\n",
      "[462]\ttraining's auc: 0.849778\ttraining's binary_logloss: 0.364092\n",
      "[463]\ttraining's auc: 0.849799\ttraining's binary_logloss: 0.364077\n",
      "[464]\ttraining's auc: 0.849818\ttraining's binary_logloss: 0.364059\n",
      "[465]\ttraining's auc: 0.849823\ttraining's binary_logloss: 0.364051\n",
      "[466]\ttraining's auc: 0.849826\ttraining's binary_logloss: 0.364042\n",
      "[467]\ttraining's auc: 0.849832\ttraining's binary_logloss: 0.36403\n",
      "[468]\ttraining's auc: 0.849837\ttraining's binary_logloss: 0.364018\n",
      "[469]\ttraining's auc: 0.849858\ttraining's binary_logloss: 0.364005\n",
      "[470]\ttraining's auc: 0.849862\ttraining's binary_logloss: 0.363993\n",
      "[471]\ttraining's auc: 0.849869\ttraining's binary_logloss: 0.363976\n",
      "[472]\ttraining's auc: 0.849879\ttraining's binary_logloss: 0.363964\n",
      "[473]\ttraining's auc: 0.849893\ttraining's binary_logloss: 0.363947\n",
      "[474]\ttraining's auc: 0.849907\ttraining's binary_logloss: 0.363926\n",
      "[475]\ttraining's auc: 0.849913\ttraining's binary_logloss: 0.363913\n",
      "[476]\ttraining's auc: 0.849918\ttraining's binary_logloss: 0.363902\n",
      "[477]\ttraining's auc: 0.849931\ttraining's binary_logloss: 0.36389\n",
      "[478]\ttraining's auc: 0.849941\ttraining's binary_logloss: 0.363878\n",
      "[479]\ttraining's auc: 0.849945\ttraining's binary_logloss: 0.363866\n",
      "[480]\ttraining's auc: 0.849951\ttraining's binary_logloss: 0.363857\n",
      "[481]\ttraining's auc: 0.849957\ttraining's binary_logloss: 0.363842\n",
      "[482]\ttraining's auc: 0.849961\ttraining's binary_logloss: 0.363834\n",
      "[483]\ttraining's auc: 0.849969\ttraining's binary_logloss: 0.363818\n",
      "[484]\ttraining's auc: 0.84998\ttraining's binary_logloss: 0.363803\n",
      "[485]\ttraining's auc: 0.849999\ttraining's binary_logloss: 0.363788\n",
      "[486]\ttraining's auc: 0.850009\ttraining's binary_logloss: 0.363772\n",
      "[487]\ttraining's auc: 0.850024\ttraining's binary_logloss: 0.363758\n",
      "[488]\ttraining's auc: 0.85003\ttraining's binary_logloss: 0.363751\n",
      "[489]\ttraining's auc: 0.850035\ttraining's binary_logloss: 0.363741\n",
      "[490]\ttraining's auc: 0.850042\ttraining's binary_logloss: 0.363727\n",
      "[491]\ttraining's auc: 0.850054\ttraining's binary_logloss: 0.363714\n",
      "[492]\ttraining's auc: 0.850075\ttraining's binary_logloss: 0.363699\n",
      "[493]\ttraining's auc: 0.850088\ttraining's binary_logloss: 0.363685\n",
      "[494]\ttraining's auc: 0.850103\ttraining's binary_logloss: 0.363674\n",
      "[495]\ttraining's auc: 0.85011\ttraining's binary_logloss: 0.363659\n",
      "[496]\ttraining's auc: 0.850116\ttraining's binary_logloss: 0.363648\n",
      "[497]\ttraining's auc: 0.850127\ttraining's binary_logloss: 0.363639\n",
      "[498]\ttraining's auc: 0.850137\ttraining's binary_logloss: 0.363625\n",
      "[499]\ttraining's auc: 0.850145\ttraining's binary_logloss: 0.36361\n",
      "[500]\ttraining's auc: 0.85015\ttraining's binary_logloss: 0.363598\n",
      "[501]\ttraining's auc: 0.850162\ttraining's binary_logloss: 0.363589\n",
      "[502]\ttraining's auc: 0.85018\ttraining's binary_logloss: 0.363574\n",
      "[503]\ttraining's auc: 0.850196\ttraining's binary_logloss: 0.36356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[504]\ttraining's auc: 0.850213\ttraining's binary_logloss: 0.36355\n",
      "[505]\ttraining's auc: 0.850225\ttraining's binary_logloss: 0.363535\n",
      "[506]\ttraining's auc: 0.850232\ttraining's binary_logloss: 0.363524\n",
      "[507]\ttraining's auc: 0.850238\ttraining's binary_logloss: 0.363509\n",
      "[508]\ttraining's auc: 0.850253\ttraining's binary_logloss: 0.363498\n",
      "[509]\ttraining's auc: 0.85026\ttraining's binary_logloss: 0.363486\n",
      "[510]\ttraining's auc: 0.850275\ttraining's binary_logloss: 0.363477\n",
      "[511]\ttraining's auc: 0.850281\ttraining's binary_logloss: 0.363464\n",
      "[512]\ttraining's auc: 0.850297\ttraining's binary_logloss: 0.36345\n",
      "[513]\ttraining's auc: 0.850302\ttraining's binary_logloss: 0.363442\n",
      "[514]\ttraining's auc: 0.850314\ttraining's binary_logloss: 0.363429\n",
      "[515]\ttraining's auc: 0.850316\ttraining's binary_logloss: 0.363421\n",
      "[516]\ttraining's auc: 0.850319\ttraining's binary_logloss: 0.363414\n",
      "[517]\ttraining's auc: 0.850329\ttraining's binary_logloss: 0.363397\n",
      "[518]\ttraining's auc: 0.850344\ttraining's binary_logloss: 0.363384\n",
      "[519]\ttraining's auc: 0.850356\ttraining's binary_logloss: 0.363371\n",
      "[520]\ttraining's auc: 0.850364\ttraining's binary_logloss: 0.363359\n",
      "[521]\ttraining's auc: 0.850366\ttraining's binary_logloss: 0.363351\n",
      "[522]\ttraining's auc: 0.850369\ttraining's binary_logloss: 0.363342\n",
      "[523]\ttraining's auc: 0.850375\ttraining's binary_logloss: 0.363329\n",
      "[524]\ttraining's auc: 0.850387\ttraining's binary_logloss: 0.363316\n",
      "[525]\ttraining's auc: 0.850396\ttraining's binary_logloss: 0.363304\n",
      "[526]\ttraining's auc: 0.850406\ttraining's binary_logloss: 0.363289\n",
      "[527]\ttraining's auc: 0.850415\ttraining's binary_logloss: 0.363278\n",
      "[528]\ttraining's auc: 0.85042\ttraining's binary_logloss: 0.363269\n",
      "[529]\ttraining's auc: 0.850426\ttraining's binary_logloss: 0.363257\n",
      "[530]\ttraining's auc: 0.850444\ttraining's binary_logloss: 0.36324\n",
      "[531]\ttraining's auc: 0.850453\ttraining's binary_logloss: 0.363228\n",
      "[532]\ttraining's auc: 0.850458\ttraining's binary_logloss: 0.363216\n",
      "[533]\ttraining's auc: 0.850475\ttraining's binary_logloss: 0.363205\n",
      "[534]\ttraining's auc: 0.850482\ttraining's binary_logloss: 0.363193\n",
      "[535]\ttraining's auc: 0.850493\ttraining's binary_logloss: 0.363181\n",
      "[536]\ttraining's auc: 0.850498\ttraining's binary_logloss: 0.36317\n",
      "[537]\ttraining's auc: 0.850508\ttraining's binary_logloss: 0.363157\n",
      "[538]\ttraining's auc: 0.850521\ttraining's binary_logloss: 0.363146\n",
      "[539]\ttraining's auc: 0.850528\ttraining's binary_logloss: 0.363132\n",
      "[540]\ttraining's auc: 0.850549\ttraining's binary_logloss: 0.363118\n",
      "[541]\ttraining's auc: 0.850567\ttraining's binary_logloss: 0.3631\n",
      "[542]\ttraining's auc: 0.850584\ttraining's binary_logloss: 0.363087\n",
      "[543]\ttraining's auc: 0.850592\ttraining's binary_logloss: 0.363078\n",
      "[544]\ttraining's auc: 0.850602\ttraining's binary_logloss: 0.363066\n",
      "[545]\ttraining's auc: 0.850615\ttraining's binary_logloss: 0.363057\n",
      "[546]\ttraining's auc: 0.850617\ttraining's binary_logloss: 0.363047\n",
      "[547]\ttraining's auc: 0.850622\ttraining's binary_logloss: 0.363036\n",
      "[548]\ttraining's auc: 0.850636\ttraining's binary_logloss: 0.363022\n",
      "[549]\ttraining's auc: 0.850645\ttraining's binary_logloss: 0.363009\n",
      "[550]\ttraining's auc: 0.85065\ttraining's binary_logloss: 0.363001\n",
      "[551]\ttraining's auc: 0.850668\ttraining's binary_logloss: 0.362992\n",
      "[552]\ttraining's auc: 0.850674\ttraining's binary_logloss: 0.362979\n",
      "[553]\ttraining's auc: 0.850689\ttraining's binary_logloss: 0.362964\n",
      "[554]\ttraining's auc: 0.850704\ttraining's binary_logloss: 0.36295\n",
      "[555]\ttraining's auc: 0.850718\ttraining's binary_logloss: 0.362935\n",
      "[556]\ttraining's auc: 0.850732\ttraining's binary_logloss: 0.362921\n",
      "[557]\ttraining's auc: 0.850737\ttraining's binary_logloss: 0.362912\n",
      "[558]\ttraining's auc: 0.85074\ttraining's binary_logloss: 0.362898\n",
      "[559]\ttraining's auc: 0.850743\ttraining's binary_logloss: 0.362891\n",
      "[560]\ttraining's auc: 0.850747\ttraining's binary_logloss: 0.362883\n",
      "[561]\ttraining's auc: 0.850752\ttraining's binary_logloss: 0.362873\n",
      "[562]\ttraining's auc: 0.850779\ttraining's binary_logloss: 0.362853\n",
      "[563]\ttraining's auc: 0.850788\ttraining's binary_logloss: 0.36284\n",
      "[564]\ttraining's auc: 0.850796\ttraining's binary_logloss: 0.362826\n",
      "[565]\ttraining's auc: 0.850812\ttraining's binary_logloss: 0.362816\n",
      "[566]\ttraining's auc: 0.850821\ttraining's binary_logloss: 0.362804\n",
      "[567]\ttraining's auc: 0.850832\ttraining's binary_logloss: 0.36279\n",
      "[568]\ttraining's auc: 0.850839\ttraining's binary_logloss: 0.362778\n",
      "[569]\ttraining's auc: 0.850852\ttraining's binary_logloss: 0.362769\n",
      "[570]\ttraining's auc: 0.850862\ttraining's binary_logloss: 0.362758\n",
      "[571]\ttraining's auc: 0.850875\ttraining's binary_logloss: 0.362745\n",
      "[572]\ttraining's auc: 0.850879\ttraining's binary_logloss: 0.362734\n",
      "[573]\ttraining's auc: 0.850886\ttraining's binary_logloss: 0.36272\n",
      "[574]\ttraining's auc: 0.850894\ttraining's binary_logloss: 0.362705\n",
      "[575]\ttraining's auc: 0.850901\ttraining's binary_logloss: 0.362689\n",
      "[576]\ttraining's auc: 0.850904\ttraining's binary_logloss: 0.362678\n",
      "[577]\ttraining's auc: 0.850911\ttraining's binary_logloss: 0.362666\n",
      "[578]\ttraining's auc: 0.850922\ttraining's binary_logloss: 0.36265\n",
      "[579]\ttraining's auc: 0.850934\ttraining's binary_logloss: 0.36263\n",
      "[580]\ttraining's auc: 0.850939\ttraining's binary_logloss: 0.362615\n",
      "[581]\ttraining's auc: 0.85095\ttraining's binary_logloss: 0.362606\n",
      "[582]\ttraining's auc: 0.850955\ttraining's binary_logloss: 0.362594\n",
      "[583]\ttraining's auc: 0.850962\ttraining's binary_logloss: 0.36258\n",
      "[584]\ttraining's auc: 0.850968\ttraining's binary_logloss: 0.362568\n",
      "[585]\ttraining's auc: 0.850972\ttraining's binary_logloss: 0.362559\n",
      "[586]\ttraining's auc: 0.850991\ttraining's binary_logloss: 0.362544\n",
      "[587]\ttraining's auc: 0.850999\ttraining's binary_logloss: 0.362528\n",
      "[588]\ttraining's auc: 0.851001\ttraining's binary_logloss: 0.362519\n",
      "[589]\ttraining's auc: 0.851006\ttraining's binary_logloss: 0.362508\n",
      "[590]\ttraining's auc: 0.851011\ttraining's binary_logloss: 0.362496\n",
      "[591]\ttraining's auc: 0.851024\ttraining's binary_logloss: 0.362486\n",
      "[592]\ttraining's auc: 0.851028\ttraining's binary_logloss: 0.362479\n",
      "[593]\ttraining's auc: 0.851035\ttraining's binary_logloss: 0.362469\n",
      "[594]\ttraining's auc: 0.851042\ttraining's binary_logloss: 0.362463\n",
      "[595]\ttraining's auc: 0.851048\ttraining's binary_logloss: 0.36245\n",
      "[596]\ttraining's auc: 0.851054\ttraining's binary_logloss: 0.362443\n",
      "[597]\ttraining's auc: 0.851059\ttraining's binary_logloss: 0.362431\n",
      "[598]\ttraining's auc: 0.85107\ttraining's binary_logloss: 0.362421\n",
      "[599]\ttraining's auc: 0.851083\ttraining's binary_logloss: 0.36241\n",
      "[600]\ttraining's auc: 0.851094\ttraining's binary_logloss: 0.362398\n",
      "[601]\ttraining's auc: 0.851105\ttraining's binary_logloss: 0.362385\n",
      "[602]\ttraining's auc: 0.851118\ttraining's binary_logloss: 0.362372\n",
      "[603]\ttraining's auc: 0.851134\ttraining's binary_logloss: 0.362358\n",
      "[604]\ttraining's auc: 0.851157\ttraining's binary_logloss: 0.362342\n",
      "[605]\ttraining's auc: 0.85117\ttraining's binary_logloss: 0.362332\n",
      "[606]\ttraining's auc: 0.851182\ttraining's binary_logloss: 0.36232\n",
      "[607]\ttraining's auc: 0.85119\ttraining's binary_logloss: 0.362309\n",
      "[608]\ttraining's auc: 0.851201\ttraining's binary_logloss: 0.362295\n",
      "[609]\ttraining's auc: 0.851208\ttraining's binary_logloss: 0.362283\n",
      "[610]\ttraining's auc: 0.851214\ttraining's binary_logloss: 0.362272\n",
      "[611]\ttraining's auc: 0.851223\ttraining's binary_logloss: 0.362257\n",
      "[612]\ttraining's auc: 0.851229\ttraining's binary_logloss: 0.362245\n",
      "[613]\ttraining's auc: 0.851236\ttraining's binary_logloss: 0.362228\n",
      "[614]\ttraining's auc: 0.851249\ttraining's binary_logloss: 0.362217\n",
      "[615]\ttraining's auc: 0.851263\ttraining's binary_logloss: 0.362208\n",
      "[616]\ttraining's auc: 0.851274\ttraining's binary_logloss: 0.362196\n",
      "[617]\ttraining's auc: 0.851293\ttraining's binary_logloss: 0.36218\n",
      "[618]\ttraining's auc: 0.851303\ttraining's binary_logloss: 0.362167\n",
      "[619]\ttraining's auc: 0.85131\ttraining's binary_logloss: 0.36215\n",
      "[620]\ttraining's auc: 0.851318\ttraining's binary_logloss: 0.362139\n",
      "[621]\ttraining's auc: 0.851334\ttraining's binary_logloss: 0.362127\n",
      "[622]\ttraining's auc: 0.851349\ttraining's binary_logloss: 0.362111\n",
      "[623]\ttraining's auc: 0.851352\ttraining's binary_logloss: 0.362102\n",
      "[624]\ttraining's auc: 0.851358\ttraining's binary_logloss: 0.362091\n",
      "[625]\ttraining's auc: 0.85136\ttraining's binary_logloss: 0.362082\n",
      "[626]\ttraining's auc: 0.851367\ttraining's binary_logloss: 0.362071\n",
      "[627]\ttraining's auc: 0.851374\ttraining's binary_logloss: 0.362057\n",
      "[628]\ttraining's auc: 0.851383\ttraining's binary_logloss: 0.362045\n",
      "[629]\ttraining's auc: 0.851387\ttraining's binary_logloss: 0.362038\n",
      "[630]\ttraining's auc: 0.851398\ttraining's binary_logloss: 0.362023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[631]\ttraining's auc: 0.851403\ttraining's binary_logloss: 0.362013\n",
      "[632]\ttraining's auc: 0.85141\ttraining's binary_logloss: 0.362001\n",
      "[633]\ttraining's auc: 0.851414\ttraining's binary_logloss: 0.361992\n",
      "[634]\ttraining's auc: 0.851419\ttraining's binary_logloss: 0.361981\n",
      "[635]\ttraining's auc: 0.851423\ttraining's binary_logloss: 0.361972\n",
      "[636]\ttraining's auc: 0.851435\ttraining's binary_logloss: 0.361963\n",
      "[637]\ttraining's auc: 0.851438\ttraining's binary_logloss: 0.361955\n",
      "[638]\ttraining's auc: 0.851463\ttraining's binary_logloss: 0.361939\n",
      "[639]\ttraining's auc: 0.851481\ttraining's binary_logloss: 0.361928\n",
      "[640]\ttraining's auc: 0.851487\ttraining's binary_logloss: 0.361918\n",
      "[641]\ttraining's auc: 0.851489\ttraining's binary_logloss: 0.361913\n",
      "[642]\ttraining's auc: 0.851498\ttraining's binary_logloss: 0.361904\n",
      "[643]\ttraining's auc: 0.851516\ttraining's binary_logloss: 0.36189\n",
      "[644]\ttraining's auc: 0.851524\ttraining's binary_logloss: 0.361882\n",
      "[645]\ttraining's auc: 0.851527\ttraining's binary_logloss: 0.361874\n",
      "[646]\ttraining's auc: 0.851533\ttraining's binary_logloss: 0.361862\n",
      "[647]\ttraining's auc: 0.851538\ttraining's binary_logloss: 0.361858\n",
      "[648]\ttraining's auc: 0.851545\ttraining's binary_logloss: 0.361842\n",
      "[649]\ttraining's auc: 0.851556\ttraining's binary_logloss: 0.361827\n",
      "[650]\ttraining's auc: 0.851572\ttraining's binary_logloss: 0.361815\n",
      "[651]\ttraining's auc: 0.851582\ttraining's binary_logloss: 0.361805\n",
      "[652]\ttraining's auc: 0.851585\ttraining's binary_logloss: 0.361798\n",
      "[653]\ttraining's auc: 0.851593\ttraining's binary_logloss: 0.361784\n",
      "[654]\ttraining's auc: 0.8516\ttraining's binary_logloss: 0.361773\n",
      "[655]\ttraining's auc: 0.851606\ttraining's binary_logloss: 0.361762\n",
      "[656]\ttraining's auc: 0.851612\ttraining's binary_logloss: 0.361746\n",
      "[657]\ttraining's auc: 0.851617\ttraining's binary_logloss: 0.361738\n",
      "[658]\ttraining's auc: 0.851627\ttraining's binary_logloss: 0.361719\n",
      "[659]\ttraining's auc: 0.85163\ttraining's binary_logloss: 0.361712\n",
      "[660]\ttraining's auc: 0.85164\ttraining's binary_logloss: 0.361697\n",
      "[661]\ttraining's auc: 0.851645\ttraining's binary_logloss: 0.361688\n",
      "[662]\ttraining's auc: 0.851653\ttraining's binary_logloss: 0.361677\n",
      "[663]\ttraining's auc: 0.851664\ttraining's binary_logloss: 0.361663\n",
      "[664]\ttraining's auc: 0.851666\ttraining's binary_logloss: 0.361654\n",
      "[665]\ttraining's auc: 0.851674\ttraining's binary_logloss: 0.361639\n",
      "[666]\ttraining's auc: 0.851683\ttraining's binary_logloss: 0.361627\n",
      "[667]\ttraining's auc: 0.851692\ttraining's binary_logloss: 0.361615\n",
      "[668]\ttraining's auc: 0.851697\ttraining's binary_logloss: 0.361605\n",
      "[669]\ttraining's auc: 0.851715\ttraining's binary_logloss: 0.361589\n",
      "[670]\ttraining's auc: 0.851729\ttraining's binary_logloss: 0.361577\n",
      "[671]\ttraining's auc: 0.851736\ttraining's binary_logloss: 0.361564\n",
      "[672]\ttraining's auc: 0.851756\ttraining's binary_logloss: 0.36155\n",
      "[673]\ttraining's auc: 0.851767\ttraining's binary_logloss: 0.361539\n",
      "[674]\ttraining's auc: 0.851773\ttraining's binary_logloss: 0.361528\n",
      "[675]\ttraining's auc: 0.851783\ttraining's binary_logloss: 0.361511\n",
      "[676]\ttraining's auc: 0.851804\ttraining's binary_logloss: 0.361496\n",
      "[677]\ttraining's auc: 0.851817\ttraining's binary_logloss: 0.361483\n",
      "[678]\ttraining's auc: 0.851834\ttraining's binary_logloss: 0.361473\n",
      "[679]\ttraining's auc: 0.851837\ttraining's binary_logloss: 0.36146\n",
      "[680]\ttraining's auc: 0.851842\ttraining's binary_logloss: 0.361456\n",
      "[681]\ttraining's auc: 0.85185\ttraining's binary_logloss: 0.361448\n",
      "[682]\ttraining's auc: 0.851855\ttraining's binary_logloss: 0.361438\n",
      "[683]\ttraining's auc: 0.851857\ttraining's binary_logloss: 0.361432\n",
      "[684]\ttraining's auc: 0.851862\ttraining's binary_logloss: 0.361419\n",
      "[685]\ttraining's auc: 0.851876\ttraining's binary_logloss: 0.361404\n",
      "[686]\ttraining's auc: 0.851893\ttraining's binary_logloss: 0.361393\n",
      "[687]\ttraining's auc: 0.851908\ttraining's binary_logloss: 0.36138\n",
      "[688]\ttraining's auc: 0.851916\ttraining's binary_logloss: 0.361371\n",
      "[689]\ttraining's auc: 0.851927\ttraining's binary_logloss: 0.361359\n",
      "[690]\ttraining's auc: 0.851931\ttraining's binary_logloss: 0.361349\n",
      "[691]\ttraining's auc: 0.851938\ttraining's binary_logloss: 0.361336\n",
      "[692]\ttraining's auc: 0.851949\ttraining's binary_logloss: 0.361325\n",
      "[693]\ttraining's auc: 0.851954\ttraining's binary_logloss: 0.361317\n",
      "[694]\ttraining's auc: 0.851956\ttraining's binary_logloss: 0.361312\n",
      "[695]\ttraining's auc: 0.851958\ttraining's binary_logloss: 0.361305\n",
      "[696]\ttraining's auc: 0.851961\ttraining's binary_logloss: 0.361293\n",
      "[697]\ttraining's auc: 0.851973\ttraining's binary_logloss: 0.361281\n",
      "[698]\ttraining's auc: 0.851979\ttraining's binary_logloss: 0.36127\n",
      "[699]\ttraining's auc: 0.851988\ttraining's binary_logloss: 0.361258\n",
      "[700]\ttraining's auc: 0.851994\ttraining's binary_logloss: 0.361249\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[700]\ttraining's auc: 0.851994\ttraining's binary_logloss: 0.361249\n",
      "Best: 0.846008 using {'num_leaves': 10, 'n_estimators': 700, 'min_child_weight': 5, 'max_depth': 9, 'learning_rate': 0.05, 'colsample_bytree': 0.9000000000000001}\n"
     ]
    }
   ],
   "source": [
    "def execute_pipeline():\n",
    "    \n",
    "    df = read_data()\n",
    "    df = reduce_mem_usage(df, True)\n",
    "    df = transform_data(df)\n",
    "    df = feature_engineering(df, break_point)\n",
    "    run_lgb(df)\n",
    "\n",
    "execute_pipeline()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
