{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective of the notebook:\n",
    "\n",
    "In this notebook, we create a machine learning model pipeline to predict probabilities and calculate model scores.\n",
    "- Importing libraries\n",
    "- Importing datasets\n",
    "- Change datatypes and reduce memory usage\n",
    "- Label encode categorical features (Features already encoded for this task.)\n",
    "- Fill null values\n",
    "- Convert raw data to a session format\n",
    "- Run the xgboost model\n",
    "- Calculate model scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T17:41:05.428122Z",
     "start_time": "2020-10-11T17:41:02.138050Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import xgboost\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "kfold = KFold(n_splits=5, random_state=42)\n",
    "break_point = datetime(2017, 2, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T17:41:05.439612Z",
     "start_time": "2020-10-11T17:41:05.431357Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    print('Reading files...')    \n",
    "    order_df = pd.read_csv('../input/machine_learning_challenge_order_data.csv')\n",
    "    print('Order data has {} rows and {} columns'.format(order_df.shape[0], order_df.shape[1]))\n",
    "    label_df = pd.read_csv('../input/machine_learning_challenge_labeled_data.csv')\n",
    "    print('Label data has {} rows and {} columns'.format(label_df.shape[0], label_df.shape[1]))\n",
    "    df = order_df.merge(label_df, on='customer_id')\n",
    "    print('The final data has {} rows and {} columns'.format(df.shape[0], df.shape[1]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change data types and reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T17:41:05.452924Z",
     "start_time": "2020-10-11T17:41:05.442835Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=False):\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    int_columns = df.select_dtypes(include=[\"int\"]).columns\n",
    "    float_columns = df.select_dtypes(include=[\"float\"]).columns\n",
    "\n",
    "    for col in int_columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
    "\n",
    "    for col in float_columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"float\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T17:41:05.461859Z",
     "start_time": "2020-10-11T17:41:05.456248Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "\n",
    "    for i in ['restaurant_id', 'city_id', 'payment_id', 'platform_id', 'transmission_id']:\n",
    "        df[i] = labelencoder.fit_transform(df[i])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert raw data to a session format\n",
    "Fill the order rank with the forward-filling method. As a baseline model, we only keep the last record of each customer. Because we assume that the last record of a user gives more info such as recency, order count, cancel, etc.)\n",
    "\n",
    "For modeling, we chose the tree-based xgboost model because it is easy to implement and ready for production in cloud services and also more successful in tabular datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T17:41:05.470768Z",
     "start_time": "2020-10-11T17:41:05.465252Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df, break_point):\n",
    "\n",
    "    df['customer_order_rank'] = df['customer_order_rank'].fillna(method='ffill')\n",
    "    df = df.groupby('customer_id').last().reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run xgb model and calculate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T18:37:53.791210Z",
     "start_time": "2020-10-11T18:37:53.339578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T17:42:38.673252Z",
     "start_time": "2020-10-12T17:42:38.641228Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split,cross_val_predict,cross_val_score, KFold\n",
    "import lightgbm  \n",
    "\n",
    "kfold = KFold(n_splits=5, random_state=42) \n",
    "\n",
    "classifiers=['KNN', 'Decision Tree',  'Logistic Regression',\n",
    "             'RandomForestClassifier', 'XGBoostClassifier', 'LGBMClaffier']\n",
    "\n",
    "model=[KNeighborsClassifier(), \n",
    "       DecisionTreeClassifier(random_state=42),\n",
    "       LogisticRegression(random_state=42),\n",
    "       RandomForestClassifier(random_state=42), \n",
    "       XGBClassifier(random_state=42), \n",
    "       lightgbm.LGBMClassifier()]\n",
    "\n",
    "def cross_val(X, Y):\n",
    "    rocm=[]\n",
    "    rocstd=[]\n",
    "    accm=[]\n",
    "    accstd=[]\n",
    "    \n",
    "    for i in model:\n",
    "        cv_result = cross_val_score(i, X, Y, cv = kfold, scoring = \"roc_auc\")\n",
    "        rocm.append(cv_result.mean())\n",
    "        rocstd.append(cv_result.std())\n",
    "\n",
    "        cv_result = cross_val_score(i, X, Y, cv = kfold, scoring = \"accuracy\")\n",
    "        accm.append(cv_result.mean())\n",
    "        accstd.append(cv_result.std())\n",
    "\n",
    "    results=round(pd.DataFrame({'Roc-Auc Mean':rocm,'Roc-Auc Std':rocstd,'Acc Mean':accm,\n",
    "                                'Acc Std':accstd}, index=classifiers), 4)  \n",
    "    print(results)\n",
    "    return results.sort_values(by='Roc-Auc Mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T17:42:38.852777Z",
     "start_time": "2020-10-12T17:42:38.841271Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_xgb(df):\n",
    "    \n",
    "    y = df['is_returning_customer']\n",
    "    X = df.drop(columns=['customer_id', 'order_date', 'is_returning_customer'])    \n",
    "    \n",
    "    cross_val(X,y)\n",
    "\n",
    "    clf = xgboost.XGBClassifier(objective= 'binary:logistic', n_jobs= -1, scale_pos_weight=2)\n",
    "    \n",
    "    y_pred = cross_val_predict(clf, X, y, cv=kfold)\n",
    "    \n",
    "    print('Accuracy Score:  ',round(metrics.accuracy_score(y, y_pred), 2))\n",
    "    print('Roc Auc Score:  ',round(roc_auc_score(y, y_pred), 2))\n",
    "    print('Classification Report: \\n', classification_report(y, y_pred, target_names=['0', '1']))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute all pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-12T17:42:41.079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Order data has 786600 rows and 13 columns\n",
      "Label data has 245455 rows and 2 columns\n",
      "The final data has 786600 rows and 14 columns\n",
      "\n",
      "Mem. usage decreased to 42.76 Mb (52.5% reduction)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def execute_pipeline():\n",
    "    \n",
    "    df = read_data()\n",
    "    print()\n",
    "    df = reduce_mem_usage(df, True)\n",
    "    df = transform_data(df)\n",
    "    df = feature_engineering(df, break_point)\n",
    "    print()\n",
    "    run_xgb(df)\n",
    "    \n",
    "execute_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is next? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy and roc-auc scores are 0.8 and 0.7 relatively. \n",
    "\n",
    "We give more weights on class 1 using the scale pos weight parameter to label returned customers more correctly. In other words, we weight roc-auc rather than accuracy.\n",
    "\n",
    "We will add recency and time-related features for the new version and compare model results with the baseline model."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
