{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective of the notebook:\n",
    "\n",
    "In this notebook, we will add recency, number of days from the first order, year, month, week, day, is weekend features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T07:56:47.022138Z",
     "start_time": "2020-10-14T07:56:47.017418Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import lightgbm \n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "break_point = datetime(2017, 2, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T07:53:53.160825Z",
     "start_time": "2020-10-14T07:53:53.156806Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    print('Reading files...')    \n",
    "    order_df = pd.read_csv('../input/machine_learning_challenge_order_data.csv')\n",
    "    print('Order data has {} rows and {} columns'.format(order_df.shape[0], order_df.shape[1]))\n",
    "    label_df = pd.read_csv('../input/machine_learning_challenge_labeled_data.csv')\n",
    "    print('Label data has {} rows and {} columns'.format(label_df.shape[0], label_df.shape[1]))\n",
    "    df = order_df.merge(label_df, on='customer_id')\n",
    "    print('The final data has {} rows and {} columns'.format(df.shape[0], df.shape[1]))\n",
    "    print(\"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change data types and reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T07:53:53.169781Z",
     "start_time": "2020-10-14T07:53:53.162272Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=False):\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    int_columns = df.select_dtypes(include=[\"int\"]).columns\n",
    "    float_columns = df.select_dtypes(include=[\"float\"]).columns\n",
    "\n",
    "    for col in int_columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
    "\n",
    "    for col in float_columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"float\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    print(\"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T07:53:53.176407Z",
     "start_time": "2020-10-14T07:53:53.172389Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "\n",
    "    for i in ['restaurant_id', 'city_id', 'payment_id', 'platform_id', 'transmission_id']:\n",
    "        df[i] = labelencoder.fit_transform(df[i])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert raw data to a session format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:32:08.319345Z",
     "start_time": "2020-10-13T20:32:08.315689Z"
    }
   },
   "source": [
    "- Fill order rank with the forward-filling method.\n",
    "- Calculate recency and number of days from the first order.\n",
    "- Get time-related features like the year, month, week, day, day of the week, weekend.\n",
    "- Keep the last record of each customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T07:53:53.185161Z",
     "start_time": "2020-10-14T07:53:53.178089Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df, break_point):\n",
    "\n",
    "    df['customer_order_rank'] = df['customer_order_rank'].fillna(method='ffill')\n",
    "\n",
    "    df['order_date'] = pd.to_datetime(df['order_date']) \n",
    "    df['recency'] = (break_point - df['order_date']) / np.timedelta64(1, 'D')\n",
    "    df['first_order_date'] = df.groupby(['customer_id'])['order_date'].transform('first')\n",
    "    df['age_of_user'] = (break_point - df['first_order_date']) / np.timedelta64(1, 'D')\n",
    "\n",
    "    df['year'] = df['order_date'].dt.year\n",
    "    df['month'] = df['order_date'].dt.month\n",
    "    df['week'] = df['order_date'].dt.week\n",
    "    df['day'] = df['order_date'].dt.day\n",
    "    df['dayofweek'] = df['order_date'].dt.dayofweek\n",
    "    df[\"is_weekend\"] = df[\"dayofweek\"].isin([5, 6]).astype(np.int8)\n",
    "   \n",
    "    df = df.groupby('customer_id').last().reset_index()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the lgb model and calculate scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T08:51:37.011316Z",
     "start_time": "2020-10-14T08:51:37.004757Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_lgb(df):\n",
    "    \n",
    "    y = df['is_returning_customer']\n",
    "    X = df.drop(columns=['customer_id', 'order_date', 'is_returning_customer',\n",
    "                        'first_order_date'])    \n",
    "    \n",
    "    clf = lightgbm.LGBMClassifier(random_state=42,  scale_pos_weight=2)\n",
    "    \n",
    "    auc_mean = cross_val_score(clf, X, y, cv = kfold, scoring = \"roc_auc\").mean()\n",
    "    auc_std = cross_val_score(clf, X, y, cv = kfold, scoring = \"roc_auc\").std()\n",
    "\n",
    "    acc_mean = cross_val_score(clf, X, y, cv = kfold, scoring = \"accuracy\").mean()\n",
    "    acc_std = cross_val_score(clf, X, y, cv = kfold, scoring = \"accuracy\").std()\n",
    "    \n",
    "    result = round(pd.DataFrame({'Roc-Auc Mean':auc_mean,'Roc-Auc Std':auc_std,\n",
    "                                'Accuracy Mean':acc_mean, 'Accuracy Std':acc_std}, \n",
    "                                 index=['LGBM']), 4)                                     \n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute all pipeline\n",
    "\n",
    "The accuracy and roc-auc scores are 0.82 and 0.73 relatively. Adding features increase model scores by 2-3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T08:52:01.546182Z",
     "start_time": "2020-10-14T08:51:38.051939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Order data has 786600 rows and 13 columns\n",
      "Label data has 245455 rows and 2 columns\n",
      "The final data has 786600 rows and 14 columns\n",
      "\n",
      "Mem. usage decreased to 42.76 Mb (52.5% reduction)\n",
      "\n",
      "      Roc-Auc Mean  Roc-Auc Std  Accuracy Mean  Accuracy Std\n",
      "LGBM        0.8161       0.0015         0.8222        0.0012\n"
     ]
    }
   ],
   "source": [
    "def execute_pipeline():\n",
    "    \n",
    "    df = read_data()\n",
    "    df = reduce_mem_usage(df, True)\n",
    "    df = transform_data(df)\n",
    "    df = feature_engineering(df, break_point)\n",
    "    run_lgb(df)\n",
    "    \n",
    "execute_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T08:41:40.154381Z",
     "start_time": "2020-10-11T08:41:40.120764Z"
    }
   },
   "source": [
    "### What is next? \n",
    "\n",
    "We will add day differences between consecutive orders and rolling features in 3 days, 1, 2, 4, 12, 24 weeks, and all time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
