{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective of the notebook:\n",
    "\n",
    "We will visualize model performance and predictions in order-recency bins matrix. save client_id, y_pred, y_actual results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:47:54.795046Z",
     "start_time": "2020-10-13T19:47:53.311643Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaan.simsek/anaconda3/envs/forecasting/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import lightgbm \n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "kfold = KFold(n_splits=5, random_state=42)\n",
    "break_point = datetime(2017, 2, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:47:54.801999Z",
     "start_time": "2020-10-13T19:47:54.797769Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    print('Reading files...')    \n",
    "    order_df = pd.read_csv('../input/machine_learning_challenge_order_data.csv')\n",
    "    print('Order data has {} rows and {} columns'.format(order_df.shape[0], order_df.shape[1]))\n",
    "    label_df = pd.read_csv('../input/machine_learning_challenge_labeled_data.csv')\n",
    "    print('Label data has {} rows and {} columns'.format(label_df.shape[0], label_df.shape[1]))\n",
    "    df = order_df.merge(label_df, on='customer_id')\n",
    "    print('The final data has {} rows and {} columns'.format(df.shape[0], df.shape[1]))\n",
    "    print(\"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T20:03:09.358138Z",
     "start_time": "2020-10-12T20:03:09.231156Z"
    }
   },
   "source": [
    "### Change data types and reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:47:54.809817Z",
     "start_time": "2020-10-13T19:47:54.803793Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=False):\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    int_columns = df.select_dtypes(include=[\"int\"]).columns\n",
    "    float_columns = df.select_dtypes(include=[\"float\"]).columns\n",
    "\n",
    "    for col in int_columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
    "\n",
    "    for col in float_columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"float\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    print(\"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:47:54.814472Z",
     "start_time": "2020-10-13T19:47:54.811283Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "\n",
    "    for i in ['restaurant_id', 'city_id', 'payment_id', 'platform_id', 'transmission_id']:\n",
    "        df[i] = labelencoder.fit_transform(df[i])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert raw data to a session format\n",
    "- Fill order rank with the forward-filling method. \n",
    "- Calculate recency and number of days from the first order.\n",
    "- Get time-related features like the year, month, week, day, day of the week, weekend.\n",
    "- Add day differences between consecutive orders. \n",
    "- Calculate rolling features in 3 days, 1, 2, 4, 12, 24 weeks, and all time.\n",
    "- Keep the last record of each customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:47:54.820450Z",
     "start_time": "2020-10-13T19:47:54.815790Z"
    }
   },
   "outputs": [],
   "source": [
    "def getWeeklyDates(df, break_point):\n",
    "\n",
    "    df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "    three_day = df[df['order_date'] >= break_point - timedelta(days=3)]\n",
    "    one_week = df[df['order_date'] >= break_point - timedelta(days=7)]\n",
    "    two_week = df[df['order_date'] >= break_point - timedelta(days=14)]\n",
    "    four_week = df[df['order_date'] >= break_point - timedelta(days=28)]\n",
    "    twelve_week = df[df['order_date'] >= break_point - timedelta(days=84)]\n",
    "    twenty_four_week = df[df['order_date'] >= break_point - timedelta(days=168)]\n",
    "    all_week = df\n",
    "    return three_day, one_week, two_week, four_week, twelve_week, twenty_four_week,all_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:47:54.833612Z",
     "start_time": "2020-10-13T19:47:54.821984Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df, break_point):\n",
    "    \n",
    "    df['customer_order_rank'] = df['customer_order_rank'].fillna(method='ffill')\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['order_date']) \n",
    "    df['recency'] = (break_point - df['date']) / np.timedelta64(1, 'D')\n",
    "    df['first_order_date'] = df.groupby(['customer_id'])['date'].transform('first')\n",
    "    df['age_of_user'] = (break_point - df['first_order_date']) / np.timedelta64(1, 'D')\n",
    "\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['week'] = df['date'].dt.week\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df[\"is_weekend\"] = df[\"dayofweek\"].isin([5, 6]).astype(np.int8)\n",
    "    \n",
    "    df['demand'] = 1\n",
    "    \n",
    "    df['order_date_shift'] = df.groupby('customer_id')['date'].shift()\n",
    "    df['date_diff'] = (df['date'] - df['order_date_shift']) / np.timedelta64(1, 'D')\n",
    "\n",
    "    three_day, one_week, two_week, four_week, twelve_week, twenty_four_week,all_week = getWeeklyDates(df, break_point)\n",
    "    \n",
    "    col = ['demand', 'is_failed','voucher_amount','delivery_fee', 'amount_paid', 'date_diff']\n",
    "    three_day, one_week, two_week, four_week, twelve_week, twenty_four_week,all_week = getWeeklyDates(df, break_point)\n",
    "    three_day = three_day.groupby('customer_id')[col].mean().add_prefix('three_day_').reset_index()\n",
    "    one_week = one_week.groupby('customer_id')[col].mean().add_prefix('one_week_').reset_index()\n",
    "    two_week = two_week.groupby('customer_id')[col].mean().add_prefix('two_week_').reset_index()\n",
    "    four_week = four_week.groupby('customer_id')[col].mean().add_prefix('four_week_').reset_index()\n",
    "    twelve_week = twelve_week.groupby('customer_id')[col].mean().add_prefix('twelve_week_').reset_index()\n",
    "    twenty_four_week = twenty_four_week.groupby('customer_id')[col].mean().add_prefix('twenty_four_week_').reset_index()\n",
    "    all_week = all_week.groupby('customer_id')[col].mean().add_prefix('all_week_').reset_index()\n",
    "    \n",
    "    df = df.groupby('customer_id').last().reset_index()\n",
    "    df = df.merge(three_day, how='left').merge(one_week, how='left').merge(two_week, how='left').merge(four_week,\n",
    "    'left').merge(twelve_week,'left').merge(twenty_four_week,'left').merge(all_week,'left').reset_index()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the lgb model and calculate scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:47:54.842644Z",
     "start_time": "2020-10-13T19:47:54.834692Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_lgb(df):\n",
    "    \n",
    "    y = df['is_returning_customer']\n",
    "    X = df.drop(columns=['customer_id', 'order_date', 'date', 'is_returning_customer',\n",
    "                        'first_order_date', 'index', 'order_date_shift'])    \n",
    "    \n",
    "    clf = lightgbm.LGBMClassifier(n_jobs= -1, scale_pos_weight=2,\n",
    "                                  num_leaves= 80,\n",
    "                                 n_estimators= 800, min_child_weight= 5, max_depth= 12, \n",
    "                                  learning_rate= 0.05, colsample_bytree= 0.6000000000000001)\n",
    "                               \n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    y_pred = cross_val_predict(clf, X, y, cv=kfold)\n",
    "    \n",
    "    fig, (ax0,ax1) = plt.subplots(2,1, figsize=(10,14))\n",
    "\n",
    "    sns.heatmap(confusion_matrix(y,y_pred),annot=True,fmt='2.0f', ax=ax0).set_title('Confusion matrix')\n",
    "\n",
    "    pd.Series(clf.feature_importances_,X.columns).sort_values()[-20:].plot.barh(width=0.8, \n",
    "                                        color='navy', ax=ax1).set_title('Feature Importance')\n",
    "\n",
    "    \n",
    "    predicted = pd.DataFrame(y_pred, index=df.customer_id, columns=['y_pred']).reset_index()\n",
    "    predicted['y_actual'] = y\n",
    "    predicted = predicted.merge(df[['customer_id', 'customer_order_rank','recency']], on='customer_id')\n",
    "    #predicted.to_csv('pred.csv')\n",
    "\n",
    "    print('Accuracy Score:  ', round(metrics.accuracy_score(y, y_pred), 3))\n",
    "    print('Roc Auc Score:  ', round(roc_auc_score(y, y_pred), 3))\n",
    "    print('Classification Report: \\n', classification_report(y, y_pred, target_names=['0', '1']))\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-13T19:47:53.324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Order data has 786600 rows and 13 columns\n",
      "Label data has 245455 rows and 2 columns\n",
      "The final data has 786600 rows and 14 columns\n",
      "\n",
      "Mem. usage decreased to 42.76 Mb (52.5% reduction)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def execute_pipeline():\n",
    "    \n",
    "    df = read_data()\n",
    "    df = reduce_mem_usage(df, True)\n",
    "    df = transform_data(df)\n",
    "    df = feature_engineering(df, break_point)\n",
    "    predicted = run_lgb(df)\n",
    "    return predicted\n",
    "\n",
    "predicted = execute_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model interpretation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-13T19:47:53.327Z"
    }
   },
   "outputs": [],
   "source": [
    "order_bins = [0, 1, 4, 9, 49, 99, 999]\n",
    "order_labels = [\"1\", \"2-4\", \"5-9\", \"10-49\", \"50-99\", \"100+\"]\n",
    "predicted['order_binned'] = pd.cut(predicted['customer_order_rank'], bins=order_bins, labels=order_labels)\n",
    "\n",
    "recency_bins = [0, 7, 14, 28, 84, 168, 1680]\n",
    "recency_labels = [\"0-7\", \"8-14\", \"15-28\", \"29-84\", \"85-168\", \"168+\"]\n",
    "predicted['recency_binned'] = pd.cut(predicted['recency'], bins=recency_bins, labels=recency_labels)\n",
    "\n",
    "predicted['is_true'] = np.where(predicted.y_pred==predicted.y_actual, 1, 0)\n",
    "\n",
    "y_actual = predicted.pivot_table(columns='order_binned', \n",
    "                                     index='recency_binned', values='y_actual', aggfunc='mean')\n",
    "y_pred = predicted.pivot_table(columns='order_binned', \n",
    "                                     index='recency_binned', values='y_pred', aggfunc='mean')\n",
    "customer_count = predicted.pivot_table(columns='order_binned', \n",
    "                                     index='recency_binned', values='y_pred', aggfunc='count')\n",
    "model_performance = predicted.pivot_table(columns='order_binned', \n",
    "                                     index='recency_binned', values='is_true', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-13T19:47:53.329Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax0,ax1) = plt.subplots(1,2, figsize=(18, 8))\n",
    "\n",
    "sns.heatmap(data = round(model_performance, 2), annot = True, cmap='Blues', fmt='g', ax=ax0)\n",
    "ax0.set_title('Model Performance (accuracy)')\n",
    "ax0.set_xlabel('Order Bins')\n",
    "ax0.set_ylabel('Recency Bins')\n",
    "\n",
    "sns.heatmap(data = round(y_pred, 2), annot = True, cmap='Blues', fmt='g', ax=ax1)\n",
    "ax1.set_title('Model Prediction (y_pred)')\n",
    "ax1.set_xlabel('Order Bins')\n",
    "ax1.set_ylabel('Recency Bins')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM model labels almost all newcomers and 168+ recency customers as churn (right below)\n",
    "\n",
    "Model performance (y_pred=y_actual) is higher for 10+ customers but lower for 2-4 order and 12-24 week recency customer cohorts. (left below)\n",
    "\n",
    "We could spend more time on different models (NN, CatBoost, etc.) or tuning hyper-parameters but we should always keep in mind that it is impossible to predict all customers correctly. (no one predicts a customer with 1 order and 24+ week recency to give an order again.) \n",
    "\n",
    "For further analysis, it would be good to get geolocation data because it helps to understand whether a customer in our service area currently. (holiday, business trip, etc.)\n",
    "\n",
    "Other features especially for the last order would increase model performance: \n",
    "- Rating\n",
    "- Comment\n",
    "- Delivery time\n",
    "- Live chat experience\n",
    "- Cancel reasons (courier, rest, user, etc.)\n",
    "- Age, gender, device type, district, OS type\n",
    "\n",
    "Now, we will create a production-ready py version of the final model."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
